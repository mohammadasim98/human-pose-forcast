{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this line if you're using Colab to something like '/content/drive/MyDrive/TeamX/'\n",
    "# where TeamX is just the clone of repository on your Google Drive\n",
    "# and you have mounted the drive at /content/drive  \n",
    "# See the Tutorial Slides for more detail.\n",
    "\n",
    "# Works on your local machine but not on Colab!\n",
    "PROJECT_ROOT = '../..' \n",
    "\n",
    "# Fix this path and use this one on Colab\n",
    "# PROJECT_ROOT = '/content/drive/MyDrive/TeamX'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from os.path import join as ospj\n",
    "sys.path.append(ospj(PROJECT_ROOT, 'src'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The syntax of the command is incorrect.\n",
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\"\n",
    "\n",
    "# Change the relative paths below to absolute if running on Colab\n",
    "!mkdir -p ../../saved/models/vit\n",
    "!mv vit_b_16-c867db91.pth ../../saved/models/vit/vit.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import *\n",
    "from models.vit.model import VisionTransformer\n",
    "print(os.getcwd())\n",
    "\n",
    "weights = torch.load(ospj(PROJECT_ROOT,'saved/models/vit.pth'))\n",
    "\n",
    "model = VisionTransformer(\n",
    "            image_size=224, # Input image size (width and height)\n",
    "            patch_size=16,  # Image broken into (16 x 16) non-overlaping batches\n",
    "            num_layers=4,  # Number of blocks in the Encoder\n",
    "            num_heads=12,   # Number of heads in each Multi-\"head\" attention\n",
    "            hidden_dim=768, # Token size (length of a single token)\n",
    "            mlp_dim=3072,   # Hidden layer size of each MLP layer,\n",
    "            total_layers=12\n",
    "        )\n",
    "\n",
    "model.load_state_dict(weights, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Setup input pipeline\n",
    "\"\"\"\n",
    "from utils.config_parser import ConfigParser\n",
    "import data.threeDPW as module_data \n",
    "\n",
    "%aimport -ConfigParser # Due to an issue of pickle and auto_reload\n",
    "\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/asim-config.json'))\n",
    "\n",
    "datamodule = config.init_obj('train_loader', module_data)\n",
    "train_loader = datamodule.get_loader()\n",
    "\n",
    "datamodule = config.init_obj('validation_loader', module_data)\n",
    "val_loader = datamodule.get_loader()\n",
    "\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/asim-config.json'))\n",
    "datamodule = config.init_obj('test_loader', module_data)\n",
    "test_loader = datamodule.get_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Visualize any loader\n",
    "\"\"\"\n",
    "from utils.viz import visualize_tfrecord_dataloader\n",
    "\n",
    "# Press q multiple times to exit. Maybe a better way possible.\n",
    "# Reduce batch size in the cfgs/project/*.json for the respective loader. \n",
    "visualize_tfrecord_dataloader(val_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asim\\AppData\\Local\\Temp\\ipykernel_15424\\1051054966.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  summary(model, input_data=torch.tensor(history[0][:][0].permute(0, 3, 1, 2), dtype=torch.float), verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Conv2d: 1-1                                 [-1, 768, 14, 14]         590,592\n",
      "├─Encoder: 1-2                                [-1, 197, 768]            --\n",
      "|    └─Sequential: 2                          []                        --\n",
      "|    |    └─EncoderBlock: 3-1                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-2                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-3                 [-1, 197, 768]            7,087,872\n",
      "|    |    └─EncoderBlock: 3-4                 [-1, 197, 768]            7,087,872\n",
      "|    └─LayerNorm: 2-1                         [-1, 197, 768]            1,536\n",
      "===============================================================================================\n",
      "Total params: 28,943,616\n",
      "Trainable params: 28,943,616\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 257.20\n",
      "===============================================================================================\n",
      "Input size (MB): 8.61\n",
      "Forward/backward pass size (MB): 11.54\n",
      "Params size (MB): 110.41\n",
      "Estimated Total Size (MB): 130.56\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "for i, (history, future) in enumerate(val_loader):\n",
    "\n",
    "    summary(model, input_data=torch.tensor(history[0][:][0].permute(0, 3, 1, 2), dtype=torch.float), verbose=1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Initialize the trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw_trainer import HPPWTrainer\n",
    "\n",
    "trainer = HPPWTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss']['train'], label='train')\n",
    "plt.plot(stats['loss']['val'], label='val')\n",
    "plt.title('Classification loss history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Perform test\n",
    "\"\"\"\n",
    "\n",
    "checkpoint_dir = '0604_104809' \n",
    "path = ospj(PROJECT_ROOT, f'saved/models/hppw/{checkpoint_dir}/best_val_model.pth')\n",
    "\n",
    "trainer.load_model(path=path)\n",
    "\n",
    "result = trainer.evaluate(loader=test_loader)\n",
    "\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
