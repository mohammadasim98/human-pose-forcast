{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Change this line if you're using Colab to something like '/content/drive/MyDrive/TeamX/'\n",
    "# where TeamX is just the clone of repository on your Google Drive\n",
    "# and you have mounted the drive at /content/drive  \n",
    "# See the Tutorial Slides for more detail.\n",
    "\n",
    "# Works on your local machine but not on Colab!\n",
    "PROJECT_ROOT = '../..' \n",
    "\n",
    "# Fix this path and use this one on Colab\n",
    "# PROJECT_ROOT = '/content/drive/MyDrive/TeamX'\n",
    "\n",
    "import sys\n",
    "from os.path import join as ospj\n",
    "sys.path.append(ospj(PROJECT_ROOT, 'src'))\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(765, 4, 4)\n",
      "(2, 765, 18, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Testing the dataset by displaying the scene and the corresponding poses directly from image and annotation files.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from utils.transforms import sample\n",
    "from utils.viz import annotate_pose\n",
    "\n",
    "seq_name = \"courtyard_arguing_00\"\n",
    "seq_dir = ospj(PROJECT_ROOT,\"data\", \"3DPWPreprocessed\", \"sequenceFiles\")\n",
    "img_dir = ospj(PROJECT_ROOT,\"data\", \"3DPWPreprocessed\", \"imageFiles\")\n",
    "folder = \"train\"\n",
    "seq_path = ospj(seq_dir, folder, seq_name + \".npz\")\n",
    "\n",
    "seq = np.load(seq_path, allow_pickle=True)\n",
    "\n",
    "poses = seq[\"abs_poses\"]\n",
    "\n",
    "trans = seq[\"trans\"]\n",
    "jointPositions = seq[\"jointPositions\"]\n",
    "cam_ext = seq[\"extrinsics\"]\n",
    "cam_int = seq[\"intrinsics\"]\n",
    "pmask = seq[\"pmask\"]\n",
    "img_dir = os.path.join(img_dir, seq_name)    \n",
    "img_names = os.listdir(img_dir)\n",
    "\n",
    "cv2.namedWindow(f\"Padded Resized Image\", cv2.WINDOW_KEEPRATIO)  \n",
    "cv2.namedWindow(f\"Padding Mask\", cv2.WINDOW_KEEPRATIO)  \n",
    "print(cam_ext.shape)\n",
    "print(poses.shape)\n",
    "for id in range(poses.shape[1]):\n",
    "    img, _, root_joint, norm_pose, abs_pose = sample(id, poses, img_names, img_dir,  imsize=(384, 384, 3))    \n",
    "    img = annotate_pose(img, poses[:, id, :, :], text=True)\n",
    "    cv2.imshow(\"Padded Resized Image\", img)\n",
    "    cv2.imshow(\"Padding Mask\", pmask)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break    \n",
    "\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset: 4648\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Testing the dataset by displaying the scene and the corresponding poses from TFRecords.\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from data.threeDPW import ThreeDPWTFRecordDataset\n",
    "from utils.transforms import cvt_absolute_pose\n",
    "from utils.viz import annotate_pose, annotate_root\n",
    "\n",
    "tfrecord_path = ospj(PROJECT_ROOT,\"data\", \"3DPWPreprocessedTFRecord\", \"train.tfrecord\")\n",
    "\n",
    "dataset = ThreeDPWTFRecordDataset(tfrecord_path, history_window=15, future_window=15, batch_size=1)\n",
    "\n",
    "print(f\"Length of dataset: {len(dataset)}\")\n",
    "\n",
    "loader = dataset.get_loader()\n",
    "\n",
    "for i, (history, future) in enumerate(loader):\n",
    "    img = history[0][0][0].numpy()\n",
    "    norm_pose = history[1][0][0].numpy()\n",
    "    root_joint = history[2][0][0].numpy()\n",
    "    mask = history[3][0].numpy()\n",
    "    abs_pose = cvt_absolute_pose(root_joint=np.expand_dims(root_joint, 0), norm_pose=np.expand_dims(norm_pose, 0))\n",
    "    annoted_img = annotate_pose(img=img, pose=abs_pose, color=(255, 0, 0), radius=2, thickness=2, text=False)\n",
    "    annoted_img = annotate_root(img=annoted_img,root=np.expand_dims(root_joint, 0), color=(0, 0, 255), thickness=3)\n",
    "    cv2.imshow(\"History Image\", img)\n",
    "    cv2.imshow(\"History Mask\", mask*255)\n",
    "    \n",
    "    norm_pose = future[0][0][0].numpy()\n",
    "    root_joint = future[1][0][0].numpy()\n",
    "    abs_pose = cvt_absolute_pose(root_joint=np.expand_dims(root_joint, 0), norm_pose=np.expand_dims(norm_pose, 0))\n",
    "    annoted_img = annotate_pose(img=img, pose=abs_pose, color=(0, 255, 0), radius=2, thickness=2, text=False)\n",
    "    annoted_img = annotate_root(img=annoted_img,root=np.expand_dims(root_joint, 0), color=(0, 255, 255), thickness=3)\n",
    "    cv2.imshow(\"Future Image\", img)\n",
    "    cv2.imshow(\"Future Mask\", mask*255)\n",
    "    \n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break     \n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
