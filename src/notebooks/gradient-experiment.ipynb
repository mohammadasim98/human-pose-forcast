{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-21T19:38:26.641323Z",
     "iopub.status.busy": "2023-07-21T19:38:26.640651Z",
     "iopub.status.idle": "2023-07-21T19:38:30.478933Z",
     "shell.execute_reply": "2023-07-21T19:38:30.478137Z",
     "shell.execute_reply.started": "2023-07-21T19:38:26.641296Z"
    },
    "id": "U_yLHnXsLFzF",
    "outputId": "31480639-ccf5-4009-a866-83843258f3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tfrecord\n",
      "  Downloading tfrecord-1.14.3-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.13.4)\n",
      "Collecting crc32c\n",
      "  Downloading crc32c-2.3.post0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tfrecord) (1.23.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from tfrecord) (3.19.6)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (66.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Installing collected packages: crc32c, tfrecord\n",
      "Successfully installed crc32c-2.3.post0 tfrecord-1.14.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tfrecord wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T21:56:41.310984Z",
     "iopub.status.busy": "2023-07-21T21:56:41.310361Z",
     "iopub.status.idle": "2023-07-21T21:56:41.908845Z",
     "shell.execute_reply": "2023-07-21T21:56:41.908241Z",
     "shell.execute_reply.started": "2023-07-21T21:56:41.310957Z"
    },
    "id": "PL4UkrhsKhhU"
   },
   "outputs": [],
   "source": [
    "# Change this line if you're using Colab to something like '/content/drive/MyDrive/TeamX/'\n",
    "# where TeamX is just the clone of repository on your Google Drive\n",
    "# and you have mounted the drive at /content/drive\n",
    "# See the Tutorial Slides for more detail.\n",
    "\n",
    "# Works on your local machine but not on Colab!\n",
    "PROJECT_ROOT = '/notebooks'\n",
    "\n",
    "# Fix this path and use this one on Colab\n",
    "# PROJECT_ROOT = '/content/drive/MyDrive/TeamX'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from os.path import join as ospj\n",
    "sys.path.append(ospj(PROJECT_ROOT, 'src'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-20T08:15:08.258885Z",
     "iopub.status.busy": "2023-07-20T08:15:08.258412Z",
     "iopub.status.idle": "2023-07-20T08:15:08.340349Z",
     "shell.execute_reply": "2023-07-20T08:15:08.338963Z",
     "shell.execute_reply.started": "2023-07-20T08:15:08.258831Z"
    },
    "id": "GRJWZUMgOCAJ",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "384b37ee-cc73-4c08-a840-655b8f105779"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainer\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "trainer.model.cpu()\n",
    "del trainer.model\n",
    "del trainer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "del train_loader\n",
    "del val_loader\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-21T12:44:43.874267Z",
     "iopub.status.busy": "2023-07-21T12:44:43.873854Z",
     "iopub.status.idle": "2023-07-21T12:44:46.858966Z",
     "shell.execute_reply": "2023-07-21T12:44:46.857933Z",
     "shell.execute_reply.started": "2023-07-21T12:44:43.874239Z"
    },
    "id": "xx15rC_qKhhd",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "61c242ca-7c9d-4528-be66-7abb4096196e"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maimport\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-ConfigParser # Due to an issue of pickle and auto_reload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m config \u001b[38;5;241m=\u001b[39m ConfigParser\u001b[38;5;241m.\u001b[39mwo_args(config\u001b[38;5;241m=\u001b[39mospj(PROJECT_ROOT,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcfgs/project/gradient-config-hppw.json\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_loader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m datamodule\u001b[38;5;241m.\u001b[39mget_loader()\n\u001b[1;32m     19\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39minit_obj(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_loader\u001b[39m\u001b[38;5;124m'\u001b[39m, module_data)\n",
      "File \u001b[0;32m/notebooks/src/utils/config_parser.py:120\u001b[0m, in \u001b[0;36mConfigParser.init_obj\u001b[0;34m(self, name, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m([k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m module_args \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverwriting kwargs given in config file is not allowed\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    119\u001b[0m module_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/src/data/threeDPW.py:80\u001b[0m, in \u001b[0;36mThreeDPWTFRecordDataset.__init__\u001b[0;34m(self, data_path, n_scenes, person_id, subsample, history_window, future_window, batch_size, resize, shuffle, n_workers, prefetch_factor, transforms)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/src/data/threeDPW.py:126\u001b[0m, in \u001b[0;36mThreeDPWTFRecordDataset._cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Iterate over each scene\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scene_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[1;32m    127\u001b[0m     num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# Generate windowed representation by adding an extra dimension \u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfrecord/reader.py:221\u001b[0m, in \u001b[0;36mexample_loader\u001b[0;34m(data_path, index_path, description, shard, compression_type)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m record_iterator:\n\u001b[1;32m    220\u001b[0m     example \u001b[38;5;241m=\u001b[39m example_pb2\u001b[38;5;241m.\u001b[39mExample()\n\u001b[0;32m--> 221\u001b[0m     \u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParseFromString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m extract_feature_dict(example\u001b[38;5;241m.\u001b[39mfeatures, description, typename_mapping)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize the 2D trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw_trainer import HPPWTrainer\n",
    "from utils.config_parser import ConfigParser\n",
    "import data.threeDPW as module_data\n",
    "from utils.io import seed_everything\n",
    "\n",
    "# For fair comparisons\n",
    "seed_everything(100)\n",
    "\n",
    "%aimport -ConfigParser # Due to an issue of pickle and auto_reload\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/gradient-config-hppw.json'))\n",
    "\n",
    "datamodule = config.init_obj('train_loader', module_data)\n",
    "train_loader = datamodule.get_loader()\n",
    "\n",
    "datamodule = config.init_obj('validation_loader', module_data)\n",
    "val_loader = datamodule.get_loader()\n",
    "\n",
    "trainer = HPPWTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss']['train'], label='train')\n",
    "plt.plot(stats['loss']['val'], label='val')\n",
    "plt.title('Classification loss history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T00:13:47.829572Z",
     "iopub.status.busy": "2023-07-22T00:13:47.829031Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masim-98-12-26\u001b[0m (\u001b[33mteam-17\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/src/notebooks/wandb/run-20230722_001404-iiixxon1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/team-17/human-pose-prediction-in-the-wild/runs/iiixxon1\" target=\"_blank\">different-salad-106</a></strong> to <a href=\"https://wandb.ai/team-17/human-pose-prediction-in-the-wild\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "==> Start Training Epoch 1/70, lr=0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 loss2d: 0.161024 vim2d: 101.89591: : 100% 9152/9152 [01:31<00:00, 99.86it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "==> Finished Epoch 1/70.\n",
      "++> Evaluate at epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 1 loss2d: 0.129751 vim2d: 130.95493: : 100% 8192/8192 [00:45<00:00, 178.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 1 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth\n",
      "    epoch          : 1\n",
      "    loss2d         : 0.18079485916174376\n",
      "    vim2d          : 103.5842967000041\n",
      "    eval_loss2d    : 0.16841393797949422\n",
      "    eval_vim2d     : 98.92634315788746\n",
      "==> Start Training Epoch 2/70, lr=0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 2 loss2d: 0.175134 vim2d: 108.83148: : 100% 9152/9152 [01:28<00:00, 102.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "==> Finished Epoch 2/70.\n",
      "++> Evaluate at epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 2 loss2d: 0.130622 vim2d: 132.43903: : 100% 8192/8192 [00:45<00:00, 178.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 2 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth\n",
      "    epoch          : 2\n",
      "    loss2d         : 0.1764789417490259\n",
      "    vim2d          : 103.75671744179893\n",
      "    eval_loss2d    : 0.16811664984561503\n",
      "    eval_vim2d     : 104.11644168943167\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 3/70, lr=0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 3 loss2d: 0.172778 vim2d: 94.40908: : 100% 9152/9152 [01:28<00:00, 102.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "==> Finished Epoch 3/70.\n",
      "++> Evaluate at epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 3 loss2d: 0.129012 vim2d: 127.68192: : 100% 8192/8192 [00:45<00:00, 180.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 3 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth\n",
      "    epoch          : 3\n",
      "    loss2d         : 0.17559652749475066\n",
      "    vim2d          : 104.49990332543433\n",
      "    eval_loss2d    : 0.1670693247433519\n",
      "    eval_vim2d     : 100.27927201613784\n",
      "==> Start Training Epoch 4/70, lr=0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 4 loss2d: 0.193542 vim2d: 112.01016: : 100% 9152/9152 [01:28<00:00, 103.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "==> Finished Epoch 4/70.\n",
      "++> Evaluate at epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 4 loss2d: 0.129770 vim2d: 133.91405: : 100% 8192/8192 [00:49<00:00, 165.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 4 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth\n",
      "    epoch          : 4\n",
      "    loss2d         : 0.1750784253740644\n",
      "    vim2d          : 104.60317763748702\n",
      "    eval_loss2d    : 0.16686041244247463\n",
      "    eval_vim2d     : 105.76537766307592\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 5/70, lr=0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 5 loss2d: 0.170178 vim2d: 98.20444: : 100% 9152/9152 [01:28<00:00, 103.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "==> Finished Epoch 5/70.\n",
      "++> Evaluate at epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 5 loss2d: 0.129226 vim2d: 131.38144: : 100% 8192/8192 [00:45<00:00, 179.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 5 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth\n",
      "    epoch          : 5\n",
      "    loss2d         : 0.17483381958274574\n",
      "    vim2d          : 104.71291399335527\n",
      "    eval_loss2d    : 0.16643718077830272\n",
      "    eval_vim2d     : 104.78339195251465\n",
      "==> Start Training Epoch 6/70, lr=0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 6 loss2d: 0.176742 vim2d: 108.21286: : 100% 9152/9152 [01:28<00:00, 102.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "==> Finished Epoch 6/70.\n",
      "++> Evaluate at epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 6 loss2d: 0.128926 vim2d: 126.46317: : 100% 8192/8192 [00:45<00:00, 181.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 6 Finished.\n",
      "Patience running out... 1\n",
      "    epoch          : 6\n",
      "    loss2d         : 0.17475678182982066\n",
      "    vim2d          : 104.69905682543775\n",
      "    eval_loss2d    : 0.1668370480329031\n",
      "    eval_vim2d     : 101.79433803632855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 7/70, lr=0.000100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 7 loss2d: 0.173527 vim2d: 104.21569: : 100% 9152/9152 [01:28<00:00, 103.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 7/70.\n",
      "++> Evaluate at epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 7 loss2d: 0.129317 vim2d: 119.18178: : 100% 8192/8192 [00:45<00:00, 179.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 7 Finished.\n",
      "Patience running out... 2\n",
      "    epoch          : 7\n",
      "    loss2d         : 0.17672480872044197\n",
      "    vim2d          : 104.43462329144245\n",
      "    eval_loss2d    : 0.16857402940513566\n",
      "    eval_vim2d     : 96.31597457826138\n",
      "==> Start Training Epoch 8/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 8 loss2d: 0.184853 vim2d: 98.83341: : 100% 9152/9152 [01:31<00:00, 100.22it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 8/70.\n",
      "++> Evaluate at epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 8 loss2d: 0.129388 vim2d: 131.64545: : 100% 8192/8192 [00:45<00:00, 179.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 8 Finished.\n",
      "Patience running out... 3\n",
      "    epoch          : 8\n",
      "    loss2d         : 0.17493590045642185\n",
      "    vim2d          : 103.53035829450701\n",
      "    eval_loss2d    : 0.1672887898166664\n",
      "    eval_vim2d     : 102.8604533597827\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/per_epoch_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "==> Start Training Epoch 9/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 9 loss2d: 0.120293 vim2d: 78.44413: : 100% 9152/9152 [01:28<00:00, 103.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 9/70.\n",
      "++> Evaluate at epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 9 loss2d: 0.085361 vim2d: 98.69836: : 100% 8192/8192 [00:45<00:00, 180.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 9 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_001350/best_model.pth\n",
      "    epoch          : 9\n",
      "    loss2d         : 0.16702536305972746\n",
      "    vim2d          : 99.59222764235277\n",
      "    eval_loss2d    : 0.13059370245900936\n",
      "    eval_vim2d     : 76.20814699307084\n",
      "==> Start Training Epoch 10/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 10 loss2d: 0.124058 vim2d: 76.29868: : 100% 9152/9152 [01:29<00:00, 102.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 10/70.\n",
      "++> Evaluate at epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 10 loss2d: 0.091982 vim2d: 109.24974: : 100% 8192/8192 [00:46<00:00, 177.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 10 Finished.\n",
      "Patience running out... 1\n",
      "    epoch          : 10\n",
      "    loss2d         : 0.13284666127675063\n",
      "    vim2d          : 78.30198071886609\n",
      "    eval_loss2d    : 0.14214235362305772\n",
      "    eval_vim2d     : 87.12513506412506\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_001350/per_epoch_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "==> Start Training Epoch 11/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 11 loss2d: 0.139270 vim2d: 83.13593: : 100% 9152/9152 [01:27<00:00, 104.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 11/70.\n",
      "++> Evaluate at epoch 11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 11 loss2d: 0.086948 vim2d: 109.72702: : 100% 8192/8192 [00:45<00:00, 179.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 11 Finished.\n",
      "Patience running out... 2\n",
      "    epoch          : 11\n",
      "    loss2d         : 0.13482046622287977\n",
      "    vim2d          : 81.37449672672298\n",
      "    eval_loss2d    : 0.13874878653587075\n",
      "    eval_vim2d     : 86.3361798375845\n",
      "==> Start Training Epoch 12/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 12 loss2d: 0.148269 vim2d: 81.26949: : 100% 9152/9152 [01:30<00:00, 100.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 12/70.\n",
      "++> Evaluate at epoch 12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 12 loss2d: 0.121317 vim2d: 107.01680: :  58% 4736/8192 [00:27<00:15, 220.72it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize the 3D trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw3d_trainer import HPPW3DTrainer\n",
    "from utils.config_parser import ConfigParser\n",
    "import data.threeDPW as module_data\n",
    "from utils.io import seed_everything\n",
    "\n",
    "# For fair comparisons\n",
    "# seed_everything(599)\n",
    "\n",
    "%aimport -ConfigParser # Due to an issue of pickle and auto_reload\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/gradient-config-hppw3d.json'))\n",
    "\n",
    "datamodule = config.init_obj('train_loader', module_data)\n",
    "train_loader = datamodule.get_loader()\n",
    "\n",
    "datamodule = config.init_obj('validation_loader', module_data)\n",
    "val_loader = datamodule.get_loader()\n",
    "\n",
    "trainer = HPPW3DTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss2d']['train'], label='train2d')\n",
    "plt.plot(stats['loss2d']['val'], label='val2d')\n",
    "plt.plot(stats['loss3d']['train'], label='train3d')\n",
    "plt.plot(stats['loss3d']['val'], label='va3dl')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mpjpe')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:41:20.293149Z",
     "iopub.status.busy": "2023-07-21T23:41:20.292553Z",
     "iopub.status.idle": "2023-07-21T23:41:20.561251Z",
     "shell.execute_reply": "2023-07-21T23:41:20.560313Z",
     "shell.execute_reply.started": "2023-07-21T23:41:20.293137Z"
    },
    "id": "3QIsVuEhKhhe"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prettytable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprettytable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrettyTable\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_parameters\u001b[39m(model):\n\u001b[1;32m      3\u001b[0m     table \u001b[38;5;241m=\u001b[39m PrettyTable([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModules\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prettytable'"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "collapsed": true,
    "id": "29KWrFViKhhf",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "4e1e17a8-feac-4200-f12b-9cdeb2410560"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/203 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b387e738a317>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/hppw/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, history, future, is_teacher_forcing)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mmemory_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_seq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Get combined* local and global features from sequences of poses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/hppw/model.py\u001b[0m in \u001b[0;36mimage_encoding\u001b[0;34m(self, img_seq, mask, unroll)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# Out Shape: (batch_size*history_window, num_patches + 1, E) and (batch_size*history_window, E)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mmemory_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_global\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# Out Shape: (batch_size, history_window, num_patches + 1, E) and (batch_size, history_window, E)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, key_padding_mask)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcls_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_mask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mkey_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# Take out the CLS token (in fact \"tokens\" because we have a batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, key_padding_mask)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Take a subset of pretrained encoder layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Final layer norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/sequential.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, key_padding_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, key_padding_mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1206\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5223\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0min_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is False but in_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5224\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_in_projection_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5226\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is True but q_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4764\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4765\u001b[0;31m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4766\u001b[0m             \u001b[0;31m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4767\u001b[0m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 14.75 GiB total capacity; 14.32 GiB already allocated; 832.00 KiB free; 14.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "for i, (history, future) in enumerate(tqdm(val_loader)):\n",
    "    output = trainer.model(history, future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-21T23:41:27.991707Z",
     "iopub.status.busy": "2023-07-21T23:41:27.991117Z",
     "iopub.status.idle": "2023-07-21T23:41:28.032942Z",
     "shell.execute_reply": "2023-07-21T23:41:28.032277Z",
     "shell.execute_reply.started": "2023-07-21T23:41:27.991683Z"
    },
    "id": "WBrHWH-LUI3d",
    "outputId": "7c2d8240-38f0-4a54-e98a-0ec7bfafc41a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moutput\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:41:32.802083Z",
     "iopub.status.busy": "2023-07-21T23:41:32.801510Z",
     "iopub.status.idle": "2023-07-21T23:41:35.623304Z",
     "shell.execute_reply": "2023-07-21T23:41:35.622400Z",
     "shell.execute_reply.started": "2023-07-21T23:41:32.802053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:41:36.540589Z",
     "iopub.status.busy": "2023-07-21T23:41:36.540287Z",
     "iopub.status.idle": "2023-07-21T23:41:36.620484Z",
     "shell.execute_reply": "2023-07-21T23:41:36.619801Z",
     "shell.execute_reply.started": "2023-07-21T23:41:36.540564Z"
    },
    "id": "i8oRVKzyKhhf",
    "outputId": "33dd751c-ab3f-4397-98e3-fe09c2ebed17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                                                      Param #\n",
       "====================================================================================================\n",
       "HumanPosePredictorModel                                                     --\n",
       "├─PoseEncoder: 1-1                                                          --\n",
       "│    └─Sequential: 2-1                                                      --\n",
       "│    │    └─PoseEncoderBlock: 3-1                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-2                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-3                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-4                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-5                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-6                                           658,432\n",
       "├─VisionTransformer: 1-2                                                    768\n",
       "│    └─Conv2d: 2-2                                                          (590,592)\n",
       "│    └─Encoder: 2-3                                                         151,296\n",
       "│    │    └─MultiInputSequential: 3-7                                       (42,527,232)\n",
       "│    │    └─LayerNorm: 3-8                                                  (1,536)\n",
       "│    └─Sequential: 2-4                                                      --\n",
       "│    │    └─Linear: 3-9                                                     (769,000)\n",
       "│    └─Linear: 2-5                                                          (196,864)\n",
       "│    └─MaxPool2d: 2-6                                                       --\n",
       "├─TemporalEncoder: 1-3                                                      --\n",
       "│    └─TemporalMultiInputSequential: 2-7                                    --\n",
       "│    │    └─TemporalEncoderBlock: 3-10                                      1,582,336\n",
       "│    │    └─TemporalEncoderBlock: 3-11                                      1,582,336\n",
       "├─TemporalEncoder: 1-4                                                      --\n",
       "│    └─TemporalMultiInputSequential: 2-8                                    --\n",
       "│    │    └─TemporalEncoderBlock: 3-12                                      1,582,336\n",
       "│    │    └─TemporalEncoderBlock: 3-13                                      1,582,336\n",
       "├─PoseDecoder: 1-5                                                          --\n",
       "│    └─MultiheadAttention: 2-9                                              197,376\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-14                           65,792\n",
       "│    └─TransformerDecoderLayer: 2-10                                        --\n",
       "│    │    └─MultiheadAttention: 3-15                                        263,168\n",
       "│    │    └─MultiheadAttention: 3-16                                        263,168\n",
       "│    │    └─Linear: 3-17                                                    65,792\n",
       "│    │    └─Dropout: 3-18                                                   --\n",
       "│    │    └─Linear: 3-19                                                    65,792\n",
       "│    │    └─LayerNorm: 3-20                                                 512\n",
       "│    │    └─LayerNorm: 3-21                                                 512\n",
       "│    │    └─LayerNorm: 3-22                                                 512\n",
       "│    │    └─Dropout: 3-23                                                   --\n",
       "│    │    └─Dropout: 3-24                                                   --\n",
       "│    │    └─Dropout: 3-25                                                   --\n",
       "│    └─LayerNorm: 2-11                                                      512\n",
       "│    └─MLPBlock: 2-12                                                       --\n",
       "│    │    └─Linear: 3-26                                                    197,376\n",
       "│    │    └─GELU: 3-27                                                      --\n",
       "│    │    └─Dropout: 3-28                                                   --\n",
       "│    │    └─Linear: 3-29                                                    196,864\n",
       "│    │    └─Dropout: 3-30                                                   --\n",
       "│    └─TransformerDecoder: 2-13                                             --\n",
       "│    │    └─ModuleList: 3-31                                                3,956,736\n",
       "│    └─TemporalEncoder: 2-14                                                --\n",
       "│    │    └─TemporalMultiInputSequential: 3-32                              2,110,464\n",
       "├─FourierMLPEncoding: 1-6                                                   --\n",
       "│    └─Sequential: 2-15                                                     --\n",
       "│    │    └─Linear: 3-33                                                    33,152\n",
       "│    │    └─ReLU: 3-34                                                      --\n",
       "│    │    └─Linear: 3-35                                                    33,024\n",
       "├─FourierMLPEncoding: 1-7                                                   --\n",
       "│    └─Sequential: 2-16                                                     --\n",
       "│    │    └─Linear: 3-36                                                    65,920\n",
       "│    │    └─ReLU: 3-37                                                      --\n",
       "│    │    └─Linear: 3-38                                                    33,024\n",
       "├─Linear: 1-8                                                               514\n",
       "====================================================================================================\n",
       "Total params: 62,067,434\n",
       "Trainable params: 17,830,146\n",
       "Non-trainable params: 44,237,288\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:50:45.616334Z",
     "iopub.status.busy": "2023-07-21T23:50:45.615757Z",
     "iopub.status.idle": "2023-07-21T23:50:45.658203Z",
     "shell.execute_reply": "2023-07-21T23:50:45.657339Z",
     "shell.execute_reply.started": "2023-07-21T23:50:45.616306Z"
    }
   },
   "outputs": [],
   "source": [
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:59:47.354553Z",
     "iopub.status.busy": "2023-07-21T23:59:47.354267Z",
     "iopub.status.idle": "2023-07-22T00:02:26.682682Z",
     "shell.execute_reply": "2023-07-22T00:02:26.682034Z",
     "shell.execute_reply.started": "2023-07-21T23:59:47.354530Z"
    },
    "id": "qfGMPX6VKhhg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: /notebooks/saved/models/gradient-HPPW3D/0721_215644/last_model.pth ...\n",
      "Checkpoint loaded.\n",
      "++> Evaluate at epoch 40 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval epoch: 40 loss2d: 0.019063 vim2d: 59.89522: : 100% 25568/25568 [02:36<00:00, 163.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 40 Finished.\n",
      "{'loss2d': 0.04572133831411731, 'vim2d': 32.24634487802007}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Perform test\n",
    "\"\"\"\n",
    "\n",
    "%aimport -ConfigParser # Due to an issue of pickle and auto_reload\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/gradient-config-hppw3d.json'))\n",
    "datamodule = config.init_obj('test_loader', module_data)\n",
    "test_loader = datamodule.get_loader()\n",
    "\n",
    "checkpoint_dir = '0721_215644' \n",
    "path = ospj(PROJECT_ROOT, f'saved/models/gradient-HPPW3D/{checkpoint_dir}/last_model.pth')\n",
    "\n",
    "trainer.load_model(path=path)\n",
    "\n",
    "result = trainer.evaluate(loader=test_loader)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AAaJjowKhhg"
   },
   "outputs": [],
   "source": [
    "from models.temporal.encoder import TemporalEncoder, LocalTemporalEncoderBlock\n",
    "\n",
    "model = TemporalEncoder(\n",
    "    num_layers=3,\n",
    "    num_heads=8,\n",
    "    hidden_dim=256,\n",
    "    mlp_dim=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdXvEna-Khhg"
   },
   "outputs": [],
   "source": [
    "local_feat = torch.randn(size=(32, 15, 197, 256))\n",
    "global_feat = torch.randn(size=(32, 15, 256))\n",
    "\n",
    "local_out, global_out = model(local_feat, global_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gObtAvw7Khhg",
    "outputId": "c8b20db4-d18a-4d69-d9df-81afea09b144"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6335],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6336],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6336],\n",
       "         ...,\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6335],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6335],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6336]],\n",
       "\n",
       "        [[-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         ...,\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401]],\n",
       "\n",
       "        [[-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         ...,\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         ...,\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412]],\n",
       "\n",
       "        [[-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         ...,\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081]],\n",
       "\n",
       "        [[ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         ...,\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AI02lLoOKhhg",
    "outputId": "4d1708e1-6d98-4ed6-ceac-0c62b89c9e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "├─MultiInputSequential: 1-1                        [-1, 197, 256]            --\n",
      "|    └─TemporalEncoderBlock: 2-1                   [-1, 14, 197, 256]        --\n",
      "|    |    └─LocalTemporalEncoderBlock: 3-1         [-1, 14, 197, 256]        528,128\n",
      "|    |    └─GlobalTemporalEncoderBlock: 3-2        [-1, 15, 256]             527,104\n",
      "|    └─TemporalEncoderBlock: 2-2                   [-1, 13, 197, 256]        --\n",
      "|    |    └─LocalTemporalEncoderBlock: 3-3         [-1, 13, 197, 256]        528,128\n",
      "|    |    └─GlobalTemporalEncoderBlock: 3-4        [-1, 15, 256]             527,104\n",
      "|    └─TemporalEncoderBlock: 2-3                   [-1, 197, 256]            --\n",
      "|    |    └─LocalTemporalEncoderBlock: 3-5         [-1, 197, 256]            528,128\n",
      "|    |    └─GlobalTemporalEncoderBlock: 3-6        [-1, 15, 256]             527,104\n",
      "====================================================================================================\n",
      "Total params: 3,165,696\n",
      "Trainable params: 3,165,696\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 21.54\n",
      "====================================================================================================\n",
      "Input size (MB): 92.81\n",
      "Forward/backward pass size (MB): 4.02\n",
      "Params size (MB): 12.08\n",
      "Estimated Total Size (MB): 108.91\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "├─MultiInputSequential: 1-1                        [-1, 197, 256]            --\n",
       "|    └─TemporalEncoderBlock: 2-1                   [-1, 14, 197, 256]        --\n",
       "|    |    └─LocalTemporalEncoderBlock: 3-1         [-1, 14, 197, 256]        528,128\n",
       "|    |    └─GlobalTemporalEncoderBlock: 3-2        [-1, 15, 256]             527,104\n",
       "|    └─TemporalEncoderBlock: 2-2                   [-1, 13, 197, 256]        --\n",
       "|    |    └─LocalTemporalEncoderBlock: 3-3         [-1, 13, 197, 256]        528,128\n",
       "|    |    └─GlobalTemporalEncoderBlock: 3-4        [-1, 15, 256]             527,104\n",
       "|    └─TemporalEncoderBlock: 2-3                   [-1, 197, 256]            --\n",
       "|    |    └─LocalTemporalEncoderBlock: 3-5         [-1, 197, 256]            528,128\n",
       "|    |    └─GlobalTemporalEncoderBlock: 3-6        [-1, 15, 256]             527,104\n",
       "====================================================================================================\n",
       "Total params: 3,165,696\n",
       "Trainable params: 3,165,696\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 21.54\n",
       "====================================================================================================\n",
       "Input size (MB): 92.81\n",
       "Forward/backward pass size (MB): 4.02\n",
       "Params size (MB): 12.08\n",
       "Estimated Total Size (MB): 108.91\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_data=[local_feat, global_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDLiJsFrKhhh",
    "outputId": "250e8f61-3e4b-4680-cb43-5f02fab5ec99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: There's no GPU available on this machine,training will be performed on CPU.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrainers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhppw_trainer\u001b[39;00m \u001b[39mimport\u001b[39;00m HPPWTrainer\n\u001b[1;32m----> 7\u001b[0m trainer \u001b[39m=\u001b[39m HPPWTrainer(config\u001b[39m=\u001b[39;49mconfig, train_loader\u001b[39m=\u001b[39;49mtrain_loader, eval_loader\u001b[39m=\u001b[39;49mval_loader)\n\u001b[0;32m      8\u001b[0m \u001b[39m# stats = trainer.train()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[39m.\u001b[39mplot(stats[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\\../..\\src\\trainers\\hppw_trainer.py:24\u001b[0m, in \u001b[0;36mHPPWTrainer.__init__\u001b[1;34m(self, config, train_loader, eval_loader)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config, train_loader, eval_loader\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     20\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m    Create the model, loss criterion, optimizer, and dataloaders\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m    And anything else that might be needed during training. (e.g. device type)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(config)    \n\u001b[0;32m     25\u001b[0m     \u001b[39m# build model architecture, then print to console\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39minit_obj(\u001b[39m'\u001b[39m\u001b[39march\u001b[39m\u001b[39m'\u001b[39m, module_arch)\n",
      "File \u001b[1;32md:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\\../..\\src\\trainers\\base.py:92\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39m# prepare for (multi-device) GPU training\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# This part doesn't do anything if you don't have a GPU.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device_ids \u001b[39m=\u001b[39m prepare_device(config[\u001b[39m'\u001b[39m\u001b[39mn_gpu\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwandb_enabled \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39;49m\u001b[39mwandb\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwandb_enabled \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mwandb\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\\../..\\src\\utils\\config_parser.py:139\u001b[0m, in \u001b[0;36mConfigParser.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m    138\u001b[0m     \u001b[39m\"\"\"Access items like ordinary dict.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[name]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'wandb'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Initialize the trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw_trainer import HPPWTrainer\n",
    "\n",
    "trainer = HPPWTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "# stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss']['train'], label='train')\n",
    "plt.plot(stats['loss']['val'], label='val')\n",
    "plt.title('Classification loss history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9R5N7uoRKhhh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
