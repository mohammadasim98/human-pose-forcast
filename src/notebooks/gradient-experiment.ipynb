{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-22T09:00:06.570862Z",
     "iopub.status.busy": "2023-07-22T09:00:06.570187Z",
     "iopub.status.idle": "2023-07-22T09:00:09.586580Z",
     "shell.execute_reply": "2023-07-22T09:00:09.585657Z",
     "shell.execute_reply.started": "2023-07-22T09:00:06.570833Z"
    },
    "id": "U_yLHnXsLFzF",
    "outputId": "31480639-ccf5-4009-a866-83843258f3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tfrecord\n",
      "  Downloading tfrecord-1.14.3-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.13.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tfrecord) (1.23.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from tfrecord) (3.19.6)\n",
      "Collecting crc32c\n",
      "  Downloading crc32c-2.3.post0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (66.1.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Installing collected packages: crc32c, tfrecord\n",
      "Successfully installed crc32c-2.3.post0 tfrecord-1.14.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tfrecord wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T09:43:01.252292Z",
     "iopub.status.busy": "2023-07-22T09:43:01.251545Z",
     "iopub.status.idle": "2023-07-22T09:43:01.872853Z",
     "shell.execute_reply": "2023-07-22T09:43:01.872131Z",
     "shell.execute_reply.started": "2023-07-22T09:43:01.252261Z"
    },
    "id": "PL4UkrhsKhhU"
   },
   "outputs": [],
   "source": [
    "# Change this line if you're using Colab to something like '/content/drive/MyDrive/TeamX/'\n",
    "# where TeamX is just the clone of repository on your Google Drive\n",
    "# and you have mounted the drive at /content/drive\n",
    "# See the Tutorial Slides for more detail.\n",
    "\n",
    "# Works on your local machine but not on Colab!\n",
    "PROJECT_ROOT = '/notebooks'\n",
    "\n",
    "# Fix this path and use this one on Colab\n",
    "# PROJECT_ROOT = '/content/drive/MyDrive/TeamX'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from os.path import join as ospj\n",
    "sys.path.append(ospj(PROJECT_ROOT, 'src'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-20T08:15:08.258885Z",
     "iopub.status.busy": "2023-07-20T08:15:08.258412Z",
     "iopub.status.idle": "2023-07-20T08:15:08.340349Z",
     "shell.execute_reply": "2023-07-20T08:15:08.338963Z",
     "shell.execute_reply.started": "2023-07-20T08:15:08.258831Z"
    },
    "id": "GRJWZUMgOCAJ",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "384b37ee-cc73-4c08-a840-655b8f105779"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainer\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "trainer.model.cpu()\n",
    "del trainer.model\n",
    "del trainer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "del train_loader\n",
    "del val_loader\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-21T12:44:43.874267Z",
     "iopub.status.busy": "2023-07-21T12:44:43.873854Z",
     "iopub.status.idle": "2023-07-21T12:44:46.858966Z",
     "shell.execute_reply": "2023-07-21T12:44:46.857933Z",
     "shell.execute_reply.started": "2023-07-21T12:44:43.874239Z"
    },
    "id": "xx15rC_qKhhd",
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "outputId": "61c242ca-7c9d-4528-be66-7abb4096196e"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maimport\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-ConfigParser # Due to an issue of pickle and auto_reload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m config \u001b[38;5;241m=\u001b[39m ConfigParser\u001b[38;5;241m.\u001b[39mwo_args(config\u001b[38;5;241m=\u001b[39mospj(PROJECT_ROOT,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcfgs/project/gradient-config-hppw.json\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_loader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m datamodule\u001b[38;5;241m.\u001b[39mget_loader()\n\u001b[1;32m     19\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39minit_obj(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_loader\u001b[39m\u001b[38;5;124m'\u001b[39m, module_data)\n",
      "File \u001b[0;32m/notebooks/src/utils/config_parser.py:120\u001b[0m, in \u001b[0;36mConfigParser.init_obj\u001b[0;34m(self, name, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m([k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m module_args \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverwriting kwargs given in config file is not allowed\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    119\u001b[0m module_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/src/data/threeDPW.py:80\u001b[0m, in \u001b[0;36mThreeDPWTFRecordDataset.__init__\u001b[0;34m(self, data_path, n_scenes, person_id, subsample, history_window, future_window, batch_size, resize, shuffle, n_workers, prefetch_factor, transforms)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/src/data/threeDPW.py:126\u001b[0m, in \u001b[0;36mThreeDPWTFRecordDataset._cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Iterate over each scene\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scene_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[1;32m    127\u001b[0m     num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# Generate windowed representation by adding an extra dimension \u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfrecord/reader.py:221\u001b[0m, in \u001b[0;36mexample_loader\u001b[0;34m(data_path, index_path, description, shard, compression_type)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m record_iterator:\n\u001b[1;32m    220\u001b[0m     example \u001b[38;5;241m=\u001b[39m example_pb2\u001b[38;5;241m.\u001b[39mExample()\n\u001b[0;32m--> 221\u001b[0m     \u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParseFromString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m extract_feature_dict(example\u001b[38;5;241m.\u001b[39mfeatures, description, typename_mapping)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize the 2D trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw_trainer import HPPWTrainer\n",
    "from utils.config_parser import ConfigParser\n",
    "import data.threeDPW as module_data\n",
    "from utils.io import seed_everything\n",
    "\n",
    "# For fair comparisons\n",
    "seed_everything(100)\n",
    "\n",
    "%aimport -ConfigParser # Due to an issue of pickle and auto_reload\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/gradient-config-hppw.json'))\n",
    "\n",
    "datamodule = config.init_obj('train_loader', module_data)\n",
    "train_loader = datamodule.get_loader()\n",
    "\n",
    "datamodule = config.init_obj('validation_loader', module_data)\n",
    "val_loader = datamodule.get_loader()\n",
    "\n",
    "trainer = HPPWTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss']['train'], label='train')\n",
    "plt.plot(stats['loss']['val'], label='val')\n",
    "plt.title('Classification loss history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-22T09:43:05.408126Z",
     "iopub.status.busy": "2023-07-22T09:43:05.407370Z",
     "iopub.status.idle": "2023-07-22T11:11:51.666830Z",
     "shell.execute_reply": "2023-07-22T11:11:51.666126Z",
     "shell.execute_reply.started": "2023-07-22T09:43:05.408095Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masim-98-12-26\u001b[0m (\u001b[33mteam-17\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/src/notebooks/wandb/run-20230722_094310-3ajx2ktn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/team-17/human-pose-prediction-in-the-wild/runs/3ajx2ktn\" target=\"_blank\">denim-smoke-109</a></strong> to <a href=\"https://wandb.ai/team-17/human-pose-prediction-in-the-wild\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Start Training Epoch 1/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 loss2d: 0.190472 vim2d: 102.76518: : 100% 9152/9152 [01:31<00:00, 99.50it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 1/70.\n",
      "++> Evaluate at epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 1 loss2d: 0.130542 vim2d: 132.83308: : 100% 8192/8192 [00:46<00:00, 175.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 1 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 1\n",
      "    loss2d         : 0.18330219471371256\n",
      "    vim2d          : 104.96644600288018\n",
      "    eval_loss2d    : 0.16947395366150886\n",
      "    eval_vim2d     : 100.21537777781487\n",
      "==> Start Training Epoch 2/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 2 loss2d: 0.180796 vim2d: 99.21544: : 100% 9152/9152 [01:31<00:00, 100.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 2/70.\n",
      "++> Evaluate at epoch 2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 2 loss2d: 0.129018 vim2d: 125.80858: : 100% 8192/8192 [00:46<00:00, 175.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 2 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 2\n",
      "    loss2d         : 0.17637801243291867\n",
      "    vim2d          : 103.79364547195968\n",
      "    eval_loss2d    : 0.16837905393913388\n",
      "    eval_vim2d     : 100.10582421720028\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 3/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 3 loss2d: 0.164499 vim2d: 104.67612: : 100% 9152/9152 [01:29<00:00, 101.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 3/70.\n",
      "++> Evaluate at epoch 3 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 3 loss2d: 0.130179 vim2d: 136.64655: : 100% 8192/8192 [00:46<00:00, 176.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 3 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 3\n",
      "    loss2d         : 0.1755434232991892\n",
      "    vim2d          : 104.38687011078521\n",
      "    eval_loss2d    : 0.16762427875073627\n",
      "    eval_vim2d     : 108.05464447289705\n",
      "==> Start Training Epoch 4/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 4 loss2d: 0.182756 vim2d: 105.15678: : 100% 9152/9152 [01:30<00:00, 101.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 4/70.\n",
      "++> Evaluate at epoch 4 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 4 loss2d: 0.129711 vim2d: 134.45270: : 100% 8192/8192 [00:49<00:00, 165.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 4 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 4\n",
      "    loss2d         : 0.17520540785956215\n",
      "    vim2d          : 104.56081694489592\n",
      "    eval_loss2d    : 0.16668966456927592\n",
      "    eval_vim2d     : 106.54149792529643\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 5/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 5 loss2d: 0.173912 vim2d: 104.34447: : 100% 9152/9152 [01:30<00:00, 101.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 5/70.\n",
      "++> Evaluate at epoch 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 5 loss2d: 0.129326 vim2d: 128.09930: : 100% 8192/8192 [00:47<00:00, 173.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 5 Finished.\n",
      "Patience running out... 1\n",
      "    epoch          : 5\n",
      "    loss2d         : 0.17482312502977732\n",
      "    vim2d          : 104.65456203647427\n",
      "    eval_loss2d    : 0.16690947047027294\n",
      "    eval_vim2d     : 101.1623401120305\n",
      "==> Start Training Epoch 6/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 6 loss2d: 0.205097 vim2d: 117.39151: : 100% 9152/9152 [01:30<00:00, 101.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.5000e-05.\n",
      "==> Finished Epoch 6/70.\n",
      "++> Evaluate at epoch 6 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 6 loss2d: 0.112367 vim2d: 125.89279: : 100% 8192/8192 [00:47<00:00, 172.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 6 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 6\n",
      "    loss2d         : 0.17615899526989542\n",
      "    vim2d          : 104.44629554481773\n",
      "    eval_loss2d    : 0.15203789400402457\n",
      "    eval_vim2d     : 99.14123706519604\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 7/70, lr=0.000085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 7 loss2d: 0.089171 vim2d: 55.04051: : 100% 9152/9152 [01:29<00:00, 102.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.2250e-05.\n",
      "==> Finished Epoch 7/70.\n",
      "++> Evaluate at epoch 7 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 7 loss2d: 0.056422 vim2d: 76.52156: : 100% 8192/8192 [00:47<00:00, 174.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 7 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 7\n",
      "    loss2d         : 0.1183776219824811\n",
      "    vim2d          : 70.92664705289828\n",
      "    eval_loss2d    : 0.10039568307547597\n",
      "    eval_vim2d     : 62.25678686797619\n",
      "==> Start Training Epoch 8/70, lr=0.000072 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 8 loss2d: 0.058400 vim2d: 20.39521: : 100% 9152/9152 [01:37<00:00, 94.00it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.2250e-05.\n",
      "==> Finished Epoch 8/70.\n",
      "++> Evaluate at epoch 8 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 8 loss2d: 0.037609 vim2d: 27.47798: : 100% 8192/8192 [00:46<00:00, 174.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 8 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 8\n",
      "    loss2d         : 0.0596334440829037\n",
      "    vim2d          : 26.35525814136425\n",
      "    eval_loss2d    : 0.06135425411048345\n",
      "    eval_vim2d     : 25.2426916398108\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 9/70, lr=0.000072 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 9 loss2d: 0.042576 vim2d: 12.39006: : 100% 9152/9152 [01:31<00:00, 99.56it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.2250e-05.\n",
      "==> Finished Epoch 9/70.\n",
      "++> Evaluate at epoch 9 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 9 loss2d: 0.035832 vim2d: 20.69005: : 100% 8192/8192 [00:47<00:00, 173.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 9 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 9\n",
      "    loss2d         : 0.04675901053356124\n",
      "    vim2d          : 15.494543375668826\n",
      "    eval_loss2d    : 0.05684596725041047\n",
      "    eval_vim2d     : 21.22304793074727\n",
      "==> Start Training Epoch 10/70, lr=0.000072 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 10 loss2d: 0.032134 vim2d: 8.15739: : 100% 9152/9152 [01:30<00:00, 100.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.2250e-05.\n",
      "==> Finished Epoch 10/70.\n",
      "++> Evaluate at epoch 10 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 10 loss2d: 0.033169 vim2d: 21.60910: : 100% 8192/8192 [00:47<00:00, 173.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 10 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 10\n",
      "    loss2d         : 0.042520058973060625\n",
      "    vim2d          : 12.373699194901473\n",
      "    eval_loss2d    : 0.05417025901260786\n",
      "    eval_vim2d     : 22.119192525744438\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 11/70, lr=0.000072 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 11 loss2d: 0.042148 vim2d: 14.30500: : 100% 9152/9152 [01:31<00:00, 100.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.2250e-05.\n",
      "==> Finished Epoch 11/70.\n",
      "++> Evaluate at epoch 11 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 11 loss2d: 0.015508 vim2d: 20.66271: : 100% 8192/8192 [00:46<00:00, 174.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 11 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 11\n",
      "    loss2d         : 0.03311805339803646\n",
      "    vim2d          : 10.560088464430162\n",
      "    eval_loss2d    : 0.03893611485545989\n",
      "    eval_vim2d     : 17.794839307665825\n",
      "==> Start Training Epoch 12/70, lr=0.000072 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 12 loss2d: 0.031085 vim2d: 12.07559: : 100% 9152/9152 [01:37<00:00, 93.74it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.2250e-05.\n",
      "==> Finished Epoch 12/70.\n",
      "++> Evaluate at epoch 12 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 12 loss2d: 0.011971 vim2d: 16.36886: : 100% 8192/8192 [00:47<00:00, 173.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 12 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 12\n",
      "    loss2d         : 0.02361078220387022\n",
      "    vim2d          : 7.811708403634024\n",
      "    eval_loss2d    : 0.03505101439805003\n",
      "    eval_vim2d     : 15.159017719328403\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 13/70, lr=0.000072 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 13 loss2d: 0.015079 vim2d: 5.59604: : 100% 9152/9152 [01:31<00:00, 100.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 7.2250e-05.\n",
      "==> Finished Epoch 13/70.\n",
      "++> Evaluate at epoch 13 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 13 loss2d: 0.018235 vim2d: 13.30420: : 100% 8192/8192 [00:46<00:00, 175.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 13 Finished.\n",
      "Patience running out... 1\n",
      "    epoch          : 13\n",
      "    loss2d         : 0.022626698407885077\n",
      "    vim2d          : 7.608486585683756\n",
      "    eval_loss2d    : 0.03636843773711007\n",
      "    eval_vim2d     : 14.918704017996788\n",
      "==> Start Training Epoch 14/70, lr=0.000072 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 14 loss2d: 0.024267 vim2d: 8.03714: : 100% 9152/9152 [01:30<00:00, 100.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.1413e-05.\n",
      "==> Finished Epoch 14/70.\n",
      "++> Evaluate at epoch 14 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 14 loss2d: 0.012309 vim2d: 16.17016: : 100% 8192/8192 [00:46<00:00, 178.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 14 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 14\n",
      "    loss2d         : 0.019693466743545517\n",
      "    vim2d          : 6.570501685976149\n",
      "    eval_loss2d    : 0.0343259199289605\n",
      "    eval_vim2d     : 14.085003294050694\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 15/70, lr=0.000061 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 15 loss2d: 0.017917 vim2d: 4.76954: : 100% 9152/9152 [01:31<00:00, 99.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.1413e-05.\n",
      "==> Finished Epoch 15/70.\n",
      "++> Evaluate at epoch 15 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 15 loss2d: 0.009107 vim2d: 11.70325: : 100% 8192/8192 [00:55<00:00, 147.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 15 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 15\n",
      "    loss2d         : 0.017977452296372893\n",
      "    vim2d          : 5.936310454682037\n",
      "    eval_loss2d    : 0.03145098940876778\n",
      "    eval_vim2d     : 13.729840753600001\n",
      "==> Start Training Epoch 16/70, lr=0.000061 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 16 loss2d: 0.014806 vim2d: 4.36668: : 100% 9152/9152 [01:31<00:00, 100.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.1413e-05.\n",
      "==> Finished Epoch 16/70.\n",
      "++> Evaluate at epoch 16 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 16 loss2d: 0.013620 vim2d: 13.40181: : 100% 8192/8192 [00:46<00:00, 176.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 16 Finished.\n",
      "Patience running out... 1\n",
      "    epoch          : 16\n",
      "    loss2d         : 0.016772583784809062\n",
      "    vim2d          : 5.493479593650444\n",
      "    eval_loss2d    : 0.0316975932510104\n",
      "    eval_vim2d     : 13.993020169436932\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "==> Start Training Epoch 17/70, lr=0.000061 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 17 loss2d: 0.015377 vim2d: 4.56686: : 100% 9152/9152 [01:30<00:00, 101.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.1413e-05.\n",
      "==> Finished Epoch 17/70.\n",
      "++> Evaluate at epoch 17 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 17 loss2d: 0.009867 vim2d: 10.55951: : 100% 8192/8192 [00:46<00:00, 175.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 17 Finished.\n",
      "Patience running out... 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch          : 17\n",
      "    loss2d         : 0.016754038938015074\n",
      "    vim2d          : 5.466056103472943\n",
      "    eval_loss2d    : 0.03265760427893838\n",
      "    eval_vim2d     : 14.32030151039362\n",
      "==> Start Training Epoch 18/70, lr=0.000061 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 18 loss2d: 0.014410 vim2d: 4.46637: : 100% 9152/9152 [01:30<00:00, 100.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.1413e-05.\n",
      "==> Finished Epoch 18/70.\n",
      "++> Evaluate at epoch 18 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 18 loss2d: 0.008433 vim2d: 12.59829: : 100% 8192/8192 [00:50<00:00, 162.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 18 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 18\n",
      "    loss2d         : 0.016542818227952175\n",
      "    vim2d          : 5.408972573447061\n",
      "    eval_loss2d    : 0.03028041877405485\n",
      "    eval_vim2d     : 12.838529476895928\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 19/70, lr=0.000061 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 19 loss2d: 0.012556 vim2d: 3.39117: : 100% 9152/9152 [01:35<00:00, 95.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.1413e-05.\n",
      "==> Finished Epoch 19/70.\n",
      "++> Evaluate at epoch 19 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 19 loss2d: 0.008495 vim2d: 11.37520: : 100% 8192/8192 [00:47<00:00, 174.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 19 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 19\n",
      "    loss2d         : 0.015781879320844905\n",
      "    vim2d          : 5.062064120819518\n",
      "    eval_loss2d    : 0.030071315602981485\n",
      "    eval_vim2d     : 12.782868037000299\n",
      "==> Start Training Epoch 20/70, lr=0.000061 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 20 loss2d: 0.022058 vim2d: 6.44603: : 100% 9152/9152 [01:30<00:00, 101.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.1413e-05.\n",
      "==> Finished Epoch 20/70.\n",
      "++> Evaluate at epoch 20 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 20 loss2d: 0.007977 vim2d: 10.17321: : 100% 8192/8192 [00:47<00:00, 172.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 20 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 20\n",
      "    loss2d         : 0.015573252064104263\n",
      "    vim2d          : 5.046391932280748\n",
      "    eval_loss2d    : 0.02890231934725307\n",
      "    eval_vim2d     : 12.382227715104818\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 21/70, lr=0.000061 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 21 loss2d: 0.018797 vim2d: 4.59959: : 100% 9152/9152 [01:30<00:00, 100.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2201e-05.\n",
      "==> Finished Epoch 21/70.\n",
      "++> Evaluate at epoch 21 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 21 loss2d: 0.012731 vim2d: 11.85913: : 100% 8192/8192 [00:47<00:00, 171.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 21 Finished.\n",
      "Patience running out... 1\n",
      "    epoch          : 21\n",
      "    loss2d         : 0.01583615586917092\n",
      "    vim2d          : 5.0692712893852825\n",
      "    eval_loss2d    : 0.03059670207585441\n",
      "    eval_vim2d     : 13.258340362459421\n",
      "==> Start Training Epoch 22/70, lr=0.000052 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 22 loss2d: 0.012839 vim2d: 3.19218: : 100% 9152/9152 [01:30<00:00, 100.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2201e-05.\n",
      "==> Finished Epoch 22/70.\n",
      "++> Evaluate at epoch 22 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 22 loss2d: 0.007221 vim2d: 9.80543: : 100% 8192/8192 [00:47<00:00, 172.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 22 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 22\n",
      "    loss2d         : 0.015459977337843055\n",
      "    vim2d          : 4.844012425496028\n",
      "    eval_loss2d    : 0.028112792773754336\n",
      "    eval_vim2d     : 12.00784419849515\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 23/70, lr=0.000052 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 23 loss2d: 0.028440 vim2d: 8.60567: : 100% 9152/9152 [01:34<00:00, 96.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2201e-05.\n",
      "==> Finished Epoch 23/70.\n",
      "++> Evaluate at epoch 23 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 23 loss2d: 0.007343 vim2d: 9.31962: : 100% 8192/8192 [00:47<00:00, 171.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 23 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 23\n",
      "    loss2d         : 0.014397445310662676\n",
      "    vim2d          : 4.508637301571719\n",
      "    eval_loss2d    : 0.027932625027460745\n",
      "    eval_vim2d     : 12.02808547206223\n",
      "==> Start Training Epoch 24/70, lr=0.000052 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 24 loss2d: 0.018861 vim2d: 6.32630: : 100% 9152/9152 [01:32<00:00, 99.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2201e-05.\n",
      "==> Finished Epoch 24/70.\n",
      "++> Evaluate at epoch 24 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 24 loss2d: 0.007956 vim2d: 10.01029: : 100% 8192/8192 [00:46<00:00, 175.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 24 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 24\n",
      "    loss2d         : 0.015268878210205715\n",
      "    vim2d          : 4.758397127364899\n",
      "    eval_loss2d    : 0.027796863636467606\n",
      "    eval_vim2d     : 11.836477652192116\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 25/70, lr=0.000052 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 25 loss2d: 0.011946 vim2d: 4.15374: : 100% 9152/9152 [01:31<00:00, 100.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2201e-05.\n",
      "==> Finished Epoch 25/70.\n",
      "++> Evaluate at epoch 25 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 25 loss2d: 0.007676 vim2d: 8.58596: : 100% 8192/8192 [00:47<00:00, 172.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 25 Finished.\n",
      "Patience running out... 1\n",
      "    epoch          : 25\n",
      "    loss2d         : 0.014143442168467111\n",
      "    vim2d          : 4.377821167032201\n",
      "    eval_loss2d    : 0.028571910541359102\n",
      "    eval_vim2d     : 12.412116395309567\n",
      "==> Start Training Epoch 26/70, lr=0.000052 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 26 loss2d: 0.006610 vim2d: 2.18733: : 100% 9152/9152 [01:31<00:00, 100.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2201e-05.\n",
      "==> Finished Epoch 26/70.\n",
      "++> Evaluate at epoch 26 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 26 loss2d: 0.011454 vim2d: 8.18763: : 100% 8192/8192 [00:50<00:00, 163.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 26 Finished.\n",
      "Patience running out... 2\n",
      "    epoch          : 26\n",
      "    loss2d         : 0.01432323594206384\n",
      "    vim2d          : 4.468927816911177\n",
      "    eval_loss2d    : 0.030229138625145424\n",
      "    eval_vim2d     : 12.341508522629738\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "==> Start Training Epoch 27/70, lr=0.000052 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 27 loss2d: 0.010046 vim2d: 3.51056: : 100% 9152/9152 [01:30<00:00, 100.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.2201e-05.\n",
      "==> Finished Epoch 27/70.\n",
      "++> Evaluate at epoch 27 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 27 loss2d: 0.006884 vim2d: 9.33204: : 100% 8192/8192 [00:47<00:00, 174.04it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 27 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 27\n",
      "    loss2d         : 0.01395071444420756\n",
      "    vim2d          : 4.31695772884609\n",
      "    eval_loss2d    : 0.02774789839895675\n",
      "    eval_vim2d     : 11.641187627799809\n",
      "==> Start Training Epoch 28/70, lr=0.000052 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 28 loss2d: 0.018178 vim2d: 4.91726: : 100% 9152/9152 [01:31<00:00, 100.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.4371e-05.\n",
      "==> Finished Epoch 28/70.\n",
      "++> Evaluate at epoch 28 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 28 loss2d: 0.007062 vim2d: 8.74088: : 100% 8192/8192 [00:46<00:00, 174.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 28 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 28\n",
      "    loss2d         : 0.013713030144572258\n",
      "    vim2d          : 4.247635104439476\n",
      "    eval_loss2d    : 0.027392953430535272\n",
      "    eval_vim2d     : 11.600921588018537\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 29/70, lr=0.000044 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 29 loss2d: 0.015791 vim2d: 7.83304: : 100% 9152/9152 [01:31<00:00, 100.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.4371e-05.\n",
      "==> Finished Epoch 29/70.\n",
      "++> Evaluate at epoch 29 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 29 loss2d: 0.006755 vim2d: 8.22079: : 100% 8192/8192 [00:47<00:00, 171.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 29 Finished.\n",
      "Patience running out... 1\n",
      "    epoch          : 29\n",
      "    loss2d         : 0.013716752911181926\n",
      "    vim2d          : 4.249310074986278\n",
      "    eval_loss2d    : 0.027418632944318233\n",
      "    eval_vim2d     : 11.636086052283645\n",
      "==> Start Training Epoch 30/70, lr=0.000044 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 30 loss2d: 0.015062 vim2d: 5.47691: : 100% 9152/9152 [01:31<00:00, 99.65it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.4371e-05.\n",
      "==> Finished Epoch 30/70.\n",
      "++> Evaluate at epoch 30 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 30 loss2d: 0.007366 vim2d: 9.41848: : 100% 8192/8192 [00:47<00:00, 173.62it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 30 Finished.\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "Saving model with best metric at /notebooks/saved/models/gradient-HPPW3D/0722_094307/best_model.pth\n",
      "    epoch          : 30\n",
      "    loss2d         : 0.013556159882956035\n",
      "    vim2d          : 4.243031665161773\n",
      "    eval_loss2d    : 0.026805067391251214\n",
      "    eval_vim2d     : 11.31749390810728\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n",
      "Checkpoint saved.\n",
      "==> Start Training Epoch 31/70, lr=0.000044 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 31 loss2d: 0.011881 vim2d: 3.53427: : 100% 9152/9152 [01:31<00:00, 99.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.4371e-05.\n",
      "==> Finished Epoch 31/70.\n",
      "++> Evaluate at epoch 31 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 31 loss2d: 0.008461 vim2d: 7.70101: : 100% 8192/8192 [00:46<00:00, 176.61it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 31 Finished.\n",
      "Patience running out... 1\n",
      "    epoch          : 31\n",
      "    loss2d         : 0.013539426315289278\n",
      "    vim2d          : 4.1277565572645285\n",
      "    eval_loss2d    : 0.028321678950305795\n",
      "    eval_vim2d     : 11.789427934214473\n",
      "==> Start Training Epoch 32/70, lr=0.000044 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 32 loss2d: 0.014772 vim2d: 4.33219: : 100% 9152/9152 [01:30<00:00, 100.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.4371e-05.\n",
      "==> Finished Epoch 32/70.\n",
      "++> Evaluate at epoch 32 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 32 loss2d: 0.007896 vim2d: 8.83495: : 100% 8192/8192 [00:47<00:00, 172.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 32 Finished.\n",
      "Patience running out... 2\n",
      "    epoch          : 32\n",
      "    loss2d         : 0.013130631395517947\n",
      "    vim2d          : 3.986788401236901\n",
      "    eval_loss2d    : 0.02707576170359971\n",
      "    eval_vim2d     : 11.488732852041721\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "==> Start Training Epoch 33/70, lr=0.000044 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 33 loss2d: 0.014409 vim2d: 3.93529: : 100% 9152/9152 [01:31<00:00, 99.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.4371e-05.\n",
      "==> Finished Epoch 33/70.\n",
      "++> Evaluate at epoch 33 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 33 loss2d: 0.006887 vim2d: 8.19385: : 100% 8192/8192 [00:47<00:00, 171.99it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 33 Finished.\n",
      "Patience running out... 3\n",
      "    epoch          : 33\n",
      "    loss2d         : 0.013319065664093811\n",
      "    vim2d          : 4.040152764820553\n",
      "    eval_loss2d    : 0.02684234314438072\n",
      "    eval_vim2d     : 11.285944979637861\n",
      "==> Start Training Epoch 34/70, lr=0.000044 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 34 loss2d: 0.011537 vim2d: 4.39136: : 100% 9152/9152 [01:33<00:00, 97.40it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.4371e-05.\n",
      "==> Finished Epoch 34/70.\n",
      "++> Evaluate at epoch 34 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 34 loss2d: 0.007877 vim2d: 8.22578: : 100% 8192/8192 [00:47<00:00, 171.88it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 34 Finished.\n",
      "Patience running out... 4\n",
      "    epoch          : 34\n",
      "    loss2d         : 0.013162034466029046\n",
      "    vim2d          : 3.996176006077053\n",
      "    eval_loss2d    : 0.026990491191099863\n",
      "    eval_vim2d     : 11.10787933319807\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "==> Start Training Epoch 35/70, lr=0.000044 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 35 loss2d: 0.012572 vim2d: 3.20559: : 100% 9152/9152 [01:32<00:00, 99.31it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.7715e-05.\n",
      "==> Finished Epoch 35/70.\n",
      "++> Evaluate at epoch 35 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 35 loss2d: 0.006915 vim2d: 8.27373: : 100% 8192/8192 [00:47<00:00, 171.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 35 Finished.\n",
      "Patience running out... 5\n",
      "    epoch          : 35\n",
      "    loss2d         : 0.013683823914221533\n",
      "    vim2d          : 4.143772448693122\n",
      "    eval_loss2d    : 0.026829899466974894\n",
      "    eval_vim2d     : 11.19716801866889\n",
      "==> Start Training Epoch 36/70, lr=0.000038 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 36 loss2d: 0.012546 vim2d: 3.11252: : 100% 9152/9152 [01:32<00:00, 99.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.7715e-05.\n",
      "==> Finished Epoch 36/70.\n",
      "++> Evaluate at epoch 36 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 36 loss2d: 0.007309 vim2d: 9.48909: : 100% 8192/8192 [00:47<00:00, 173.60it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 36 Finished.\n",
      "Patience running out... 6\n",
      "    epoch          : 36\n",
      "    loss2d         : 0.012599402478524854\n",
      "    vim2d          : 3.7480458479661207\n",
      "    eval_loss2d    : 0.02709474072617013\n",
      "    eval_vim2d     : 11.10133426450193\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/per_epoch_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n",
      "==> Start Training Epoch 37/70, lr=0.000038 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 37 loss2d: 0.012129 vim2d: 3.70636: : 100% 9152/9152 [01:31<00:00, 99.60it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.7715e-05.\n",
      "==> Finished Epoch 37/70.\n",
      "++> Evaluate at epoch 37 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 37 loss2d: 0.007111 vim2d: 9.10505: : 100% 8192/8192 [00:54<00:00, 150.76it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 37 Finished.\n",
      "Patience running out... 7\n",
      "    epoch          : 37\n",
      "    loss2d         : 0.012769134216974457\n",
      "    vim2d          : 3.8673895655812083\n",
      "    eval_loss2d    : 0.026990097721864004\n",
      "    eval_vim2d     : 11.32398497313261\n",
      "==> Start Training Epoch 38/70, lr=0.000038 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train epoch: 38 loss2d: 0.010306 vim2d: 2.93656: : 100% 9152/9152 [01:31<00:00, 100.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.7715e-05.\n",
      "==> Finished Epoch 38/70.\n",
      "++> Evaluate at epoch 38 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval epoch: 38 loss2d: 0.006509 vim2d: 8.21856: : 100% 8192/8192 [00:47<00:00, 171.28it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 38 Finished.\n",
      "No improvement so far... breaking...goodby\n",
      "Saving checkpoint: /notebooks/saved/models/gradient-HPPW3D/0722_094307/last_model.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Initialize the 3D trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw3d_trainer import HPPW3DTrainer\n",
    "from utils.config_parser import ConfigParser\n",
    "import data.threeDPW as module_data\n",
    "from utils.io import seed_everything\n",
    "\n",
    "# For fair comparisons\n",
    "# seed_everything(599)\n",
    "\n",
    "%aimport -ConfigParser # Due to an issue of pickle and auto_reload\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/gradient-config-hppw3d.json'))\n",
    "\n",
    "datamodule = config.init_obj('train_loader', module_data)\n",
    "train_loader = datamodule.get_loader()\n",
    "\n",
    "datamodule = config.init_obj('validation_loader', module_data)\n",
    "val_loader = datamodule.get_loader()\n",
    "\n",
    "trainer = HPPW3DTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss2d']['train'], label='train2d')\n",
    "plt.plot(stats['loss2d']['val'], label='val2d')\n",
    "plt.plot(stats['loss3d']['train'], label='train3d')\n",
    "plt.plot(stats['loss3d']['val'], label='va3dl')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mpjpe')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:41:20.293149Z",
     "iopub.status.busy": "2023-07-21T23:41:20.292553Z",
     "iopub.status.idle": "2023-07-21T23:41:20.561251Z",
     "shell.execute_reply": "2023-07-21T23:41:20.560313Z",
     "shell.execute_reply.started": "2023-07-21T23:41:20.293137Z"
    },
    "id": "3QIsVuEhKhhe"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prettytable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprettytable\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PrettyTable\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcount_parameters\u001b[39m(model):\n\u001b[1;32m      3\u001b[0m     table \u001b[38;5;241m=\u001b[39m PrettyTable([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModules\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'prettytable'"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "collapsed": true,
    "id": "29KWrFViKhhf",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "4e1e17a8-feac-4200-f12b-9cdeb2410560"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/203 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b387e738a317>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/hppw/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, history, future, is_teacher_forcing)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mmemory_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_seq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Get combined* local and global features from sequences of poses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/hppw/model.py\u001b[0m in \u001b[0;36mimage_encoding\u001b[0;34m(self, img_seq, mask, unroll)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# Out Shape: (batch_size*history_window, num_patches + 1, E) and (batch_size*history_window, E)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mmemory_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_global\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# Out Shape: (batch_size, history_window, num_patches + 1, E) and (batch_size, history_window, E)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, key_padding_mask)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcls_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_mask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mkey_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# Take out the CLS token (in fact \"tokens\" because we have a batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, key_padding_mask)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Take a subset of pretrained encoder layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Final layer norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/sequential.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, key_padding_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, key_padding_mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1206\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5223\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0min_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is False but in_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5224\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_in_projection_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5226\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is True but q_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4764\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4765\u001b[0;31m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4766\u001b[0m             \u001b[0;31m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4767\u001b[0m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 14.75 GiB total capacity; 14.32 GiB already allocated; 832.00 KiB free; 14.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "for i, (history, future) in enumerate(tqdm(val_loader)):\n",
    "    output = trainer.model(history, future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-21T23:41:27.991707Z",
     "iopub.status.busy": "2023-07-21T23:41:27.991117Z",
     "iopub.status.idle": "2023-07-21T23:41:28.032942Z",
     "shell.execute_reply": "2023-07-21T23:41:28.032277Z",
     "shell.execute_reply.started": "2023-07-21T23:41:27.991683Z"
    },
    "id": "WBrHWH-LUI3d",
    "outputId": "7c2d8240-38f0-4a54-e98a-0ec7bfafc41a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43moutput\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:41:32.802083Z",
     "iopub.status.busy": "2023-07-21T23:41:32.801510Z",
     "iopub.status.idle": "2023-07-21T23:41:35.623304Z",
     "shell.execute_reply": "2023-07-21T23:41:35.622400Z",
     "shell.execute_reply.started": "2023-07-21T23:41:32.802053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:41:36.540589Z",
     "iopub.status.busy": "2023-07-21T23:41:36.540287Z",
     "iopub.status.idle": "2023-07-21T23:41:36.620484Z",
     "shell.execute_reply": "2023-07-21T23:41:36.619801Z",
     "shell.execute_reply.started": "2023-07-21T23:41:36.540564Z"
    },
    "id": "i8oRVKzyKhhf",
    "outputId": "33dd751c-ab3f-4397-98e3-fe09c2ebed17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                                                      Param #\n",
       "====================================================================================================\n",
       "HumanPosePredictorModel                                                     --\n",
       "├─PoseEncoder: 1-1                                                          --\n",
       "│    └─Sequential: 2-1                                                      --\n",
       "│    │    └─PoseEncoderBlock: 3-1                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-2                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-3                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-4                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-5                                           658,432\n",
       "│    │    └─PoseEncoderBlock: 3-6                                           658,432\n",
       "├─VisionTransformer: 1-2                                                    768\n",
       "│    └─Conv2d: 2-2                                                          (590,592)\n",
       "│    └─Encoder: 2-3                                                         151,296\n",
       "│    │    └─MultiInputSequential: 3-7                                       (42,527,232)\n",
       "│    │    └─LayerNorm: 3-8                                                  (1,536)\n",
       "│    └─Sequential: 2-4                                                      --\n",
       "│    │    └─Linear: 3-9                                                     (769,000)\n",
       "│    └─Linear: 2-5                                                          (196,864)\n",
       "│    └─MaxPool2d: 2-6                                                       --\n",
       "├─TemporalEncoder: 1-3                                                      --\n",
       "│    └─TemporalMultiInputSequential: 2-7                                    --\n",
       "│    │    └─TemporalEncoderBlock: 3-10                                      1,582,336\n",
       "│    │    └─TemporalEncoderBlock: 3-11                                      1,582,336\n",
       "├─TemporalEncoder: 1-4                                                      --\n",
       "│    └─TemporalMultiInputSequential: 2-8                                    --\n",
       "│    │    └─TemporalEncoderBlock: 3-12                                      1,582,336\n",
       "│    │    └─TemporalEncoderBlock: 3-13                                      1,582,336\n",
       "├─PoseDecoder: 1-5                                                          --\n",
       "│    └─MultiheadAttention: 2-9                                              197,376\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-14                           65,792\n",
       "│    └─TransformerDecoderLayer: 2-10                                        --\n",
       "│    │    └─MultiheadAttention: 3-15                                        263,168\n",
       "│    │    └─MultiheadAttention: 3-16                                        263,168\n",
       "│    │    └─Linear: 3-17                                                    65,792\n",
       "│    │    └─Dropout: 3-18                                                   --\n",
       "│    │    └─Linear: 3-19                                                    65,792\n",
       "│    │    └─LayerNorm: 3-20                                                 512\n",
       "│    │    └─LayerNorm: 3-21                                                 512\n",
       "│    │    └─LayerNorm: 3-22                                                 512\n",
       "│    │    └─Dropout: 3-23                                                   --\n",
       "│    │    └─Dropout: 3-24                                                   --\n",
       "│    │    └─Dropout: 3-25                                                   --\n",
       "│    └─LayerNorm: 2-11                                                      512\n",
       "│    └─MLPBlock: 2-12                                                       --\n",
       "│    │    └─Linear: 3-26                                                    197,376\n",
       "│    │    └─GELU: 3-27                                                      --\n",
       "│    │    └─Dropout: 3-28                                                   --\n",
       "│    │    └─Linear: 3-29                                                    196,864\n",
       "│    │    └─Dropout: 3-30                                                   --\n",
       "│    └─TransformerDecoder: 2-13                                             --\n",
       "│    │    └─ModuleList: 3-31                                                3,956,736\n",
       "│    └─TemporalEncoder: 2-14                                                --\n",
       "│    │    └─TemporalMultiInputSequential: 3-32                              2,110,464\n",
       "├─FourierMLPEncoding: 1-6                                                   --\n",
       "│    └─Sequential: 2-15                                                     --\n",
       "│    │    └─Linear: 3-33                                                    33,152\n",
       "│    │    └─ReLU: 3-34                                                      --\n",
       "│    │    └─Linear: 3-35                                                    33,024\n",
       "├─FourierMLPEncoding: 1-7                                                   --\n",
       "│    └─Sequential: 2-16                                                     --\n",
       "│    │    └─Linear: 3-36                                                    65,920\n",
       "│    │    └─ReLU: 3-37                                                      --\n",
       "│    │    └─Linear: 3-38                                                    33,024\n",
       "├─Linear: 1-8                                                               514\n",
       "====================================================================================================\n",
       "Total params: 62,067,434\n",
       "Trainable params: 17,830,146\n",
       "Non-trainable params: 44,237,288\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:50:45.616334Z",
     "iopub.status.busy": "2023-07-21T23:50:45.615757Z",
     "iopub.status.idle": "2023-07-21T23:50:45.658203Z",
     "shell.execute_reply": "2023-07-21T23:50:45.657339Z",
     "shell.execute_reply.started": "2023-07-21T23:50:45.616306Z"
    }
   },
   "outputs": [],
   "source": [
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T23:59:47.354553Z",
     "iopub.status.busy": "2023-07-21T23:59:47.354267Z",
     "iopub.status.idle": "2023-07-22T00:02:26.682682Z",
     "shell.execute_reply": "2023-07-22T00:02:26.682034Z",
     "shell.execute_reply.started": "2023-07-21T23:59:47.354530Z"
    },
    "id": "qfGMPX6VKhhg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: /notebooks/saved/models/gradient-HPPW3D/0721_215644/last_model.pth ...\n",
      "Checkpoint loaded.\n",
      "++> Evaluate at epoch 40 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval epoch: 40 loss2d: 0.019063 vim2d: 59.89522: : 100% 25568/25568 [02:36<00:00, 163.57it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "++> Evaluate epoch 40 Finished.\n",
      "{'loss2d': 0.04572133831411731, 'vim2d': 32.24634487802007}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Perform test\n",
    "\"\"\"\n",
    "\n",
    "%aimport -ConfigParser # Due to an issue of pickle and auto_reload\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/gradient-config-hppw3d.json'))\n",
    "datamodule = config.init_obj('test_loader', module_data)\n",
    "test_loader = datamodule.get_loader()\n",
    "\n",
    "checkpoint_dir = '0721_215644' \n",
    "path = ospj(PROJECT_ROOT, f'saved/models/gradient-HPPW3D/{checkpoint_dir}/last_model.pth')\n",
    "\n",
    "trainer.load_model(path=path)\n",
    "\n",
    "result = trainer.evaluate(loader=test_loader)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AAaJjowKhhg"
   },
   "outputs": [],
   "source": [
    "from models.temporal.encoder import TemporalEncoder, LocalTemporalEncoderBlock\n",
    "\n",
    "model = TemporalEncoder(\n",
    "    num_layers=3,\n",
    "    num_heads=8,\n",
    "    hidden_dim=256,\n",
    "    mlp_dim=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdXvEna-Khhg"
   },
   "outputs": [],
   "source": [
    "local_feat = torch.randn(size=(32, 15, 197, 256))\n",
    "global_feat = torch.randn(size=(32, 15, 256))\n",
    "\n",
    "local_out, global_out = model(local_feat, global_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gObtAvw7Khhg",
    "outputId": "c8b20db4-d18a-4d69-d9df-81afea09b144"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6335],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6336],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6336],\n",
       "         ...,\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6335],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6335],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6336]],\n",
       "\n",
       "        [[-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         ...,\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401]],\n",
       "\n",
       "        [[-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         ...,\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         ...,\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412]],\n",
       "\n",
       "        [[-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         ...,\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081]],\n",
       "\n",
       "        [[ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         ...,\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AI02lLoOKhhg",
    "outputId": "4d1708e1-6d98-4ed6-ceac-0c62b89c9e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "├─MultiInputSequential: 1-1                        [-1, 197, 256]            --\n",
      "|    └─TemporalEncoderBlock: 2-1                   [-1, 14, 197, 256]        --\n",
      "|    |    └─LocalTemporalEncoderBlock: 3-1         [-1, 14, 197, 256]        528,128\n",
      "|    |    └─GlobalTemporalEncoderBlock: 3-2        [-1, 15, 256]             527,104\n",
      "|    └─TemporalEncoderBlock: 2-2                   [-1, 13, 197, 256]        --\n",
      "|    |    └─LocalTemporalEncoderBlock: 3-3         [-1, 13, 197, 256]        528,128\n",
      "|    |    └─GlobalTemporalEncoderBlock: 3-4        [-1, 15, 256]             527,104\n",
      "|    └─TemporalEncoderBlock: 2-3                   [-1, 197, 256]            --\n",
      "|    |    └─LocalTemporalEncoderBlock: 3-5         [-1, 197, 256]            528,128\n",
      "|    |    └─GlobalTemporalEncoderBlock: 3-6        [-1, 15, 256]             527,104\n",
      "====================================================================================================\n",
      "Total params: 3,165,696\n",
      "Trainable params: 3,165,696\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 21.54\n",
      "====================================================================================================\n",
      "Input size (MB): 92.81\n",
      "Forward/backward pass size (MB): 4.02\n",
      "Params size (MB): 12.08\n",
      "Estimated Total Size (MB): 108.91\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "├─MultiInputSequential: 1-1                        [-1, 197, 256]            --\n",
       "|    └─TemporalEncoderBlock: 2-1                   [-1, 14, 197, 256]        --\n",
       "|    |    └─LocalTemporalEncoderBlock: 3-1         [-1, 14, 197, 256]        528,128\n",
       "|    |    └─GlobalTemporalEncoderBlock: 3-2        [-1, 15, 256]             527,104\n",
       "|    └─TemporalEncoderBlock: 2-2                   [-1, 13, 197, 256]        --\n",
       "|    |    └─LocalTemporalEncoderBlock: 3-3         [-1, 13, 197, 256]        528,128\n",
       "|    |    └─GlobalTemporalEncoderBlock: 3-4        [-1, 15, 256]             527,104\n",
       "|    └─TemporalEncoderBlock: 2-3                   [-1, 197, 256]            --\n",
       "|    |    └─LocalTemporalEncoderBlock: 3-5         [-1, 197, 256]            528,128\n",
       "|    |    └─GlobalTemporalEncoderBlock: 3-6        [-1, 15, 256]             527,104\n",
       "====================================================================================================\n",
       "Total params: 3,165,696\n",
       "Trainable params: 3,165,696\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 21.54\n",
       "====================================================================================================\n",
       "Input size (MB): 92.81\n",
       "Forward/backward pass size (MB): 4.02\n",
       "Params size (MB): 12.08\n",
       "Estimated Total Size (MB): 108.91\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_data=[local_feat, global_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDLiJsFrKhhh",
    "outputId": "250e8f61-3e4b-4680-cb43-5f02fab5ec99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: There's no GPU available on this machine,training will be performed on CPU.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrainers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhppw_trainer\u001b[39;00m \u001b[39mimport\u001b[39;00m HPPWTrainer\n\u001b[1;32m----> 7\u001b[0m trainer \u001b[39m=\u001b[39m HPPWTrainer(config\u001b[39m=\u001b[39;49mconfig, train_loader\u001b[39m=\u001b[39;49mtrain_loader, eval_loader\u001b[39m=\u001b[39;49mval_loader)\n\u001b[0;32m      8\u001b[0m \u001b[39m# stats = trainer.train()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[39m.\u001b[39mplot(stats[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\\../..\\src\\trainers\\hppw_trainer.py:24\u001b[0m, in \u001b[0;36mHPPWTrainer.__init__\u001b[1;34m(self, config, train_loader, eval_loader)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config, train_loader, eval_loader\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     20\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m    Create the model, loss criterion, optimizer, and dataloaders\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m    And anything else that might be needed during training. (e.g. device type)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(config)    \n\u001b[0;32m     25\u001b[0m     \u001b[39m# build model architecture, then print to console\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39minit_obj(\u001b[39m'\u001b[39m\u001b[39march\u001b[39m\u001b[39m'\u001b[39m, module_arch)\n",
      "File \u001b[1;32md:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\\../..\\src\\trainers\\base.py:92\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39m# prepare for (multi-device) GPU training\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# This part doesn't do anything if you don't have a GPU.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device_ids \u001b[39m=\u001b[39m prepare_device(config[\u001b[39m'\u001b[39m\u001b[39mn_gpu\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwandb_enabled \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39;49m\u001b[39mwandb\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwandb_enabled \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mwandb\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\\../..\\src\\utils\\config_parser.py:139\u001b[0m, in \u001b[0;36mConfigParser.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m    138\u001b[0m     \u001b[39m\"\"\"Access items like ordinary dict.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[name]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'wandb'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Initialize the trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw_trainer import HPPWTrainer\n",
    "\n",
    "trainer = HPPWTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "# stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss']['train'], label='train')\n",
    "plt.plot(stats['loss']['val'], label='val')\n",
    "plt.title('Classification loss history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9R5N7uoRKhhh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
