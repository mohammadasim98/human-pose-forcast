{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-21T18:08:33.733383Z",
     "iopub.status.busy": "2023-07-21T18:08:33.732775Z",
     "iopub.status.idle": "2023-07-21T18:08:36.499643Z",
     "shell.execute_reply": "2023-07-21T18:08:36.498950Z",
     "shell.execute_reply.started": "2023-07-21T18:08:33.733357Z"
    },
    "id": "U_yLHnXsLFzF",
    "outputId": "31480639-ccf5-4009-a866-83843258f3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tfrecord\n",
      "  Downloading tfrecord-1.14.3-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (0.13.4)\n",
      "Collecting crc32c\n",
      "  Downloading crc32c-2.3.post0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.1/43.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from tfrecord) (3.19.6)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from tfrecord) (1.23.4)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.4)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.0.11)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
      "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.30)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.28.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (66.1.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Installing collected packages: crc32c, tfrecord\n",
      "Successfully installed crc32c-2.3.post0 tfrecord-1.14.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tfrecord wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T19:04:40.167147Z",
     "iopub.status.busy": "2023-07-21T19:04:40.166590Z",
     "iopub.status.idle": "2023-07-21T19:04:40.746092Z",
     "shell.execute_reply": "2023-07-21T19:04:40.736846Z",
     "shell.execute_reply.started": "2023-07-21T19:04:40.167123Z"
    },
    "id": "PL4UkrhsKhhU"
   },
   "outputs": [],
   "source": [
    "# Change this line if you're using Colab to something like '/content/drive/MyDrive/TeamX/'\n",
    "# where TeamX is just the clone of repository on your Google Drive\n",
    "# and you have mounted the drive at /content/drive\n",
    "# See the Tutorial Slides for more detail.\n",
    "\n",
    "# Works on your local machine but not on Colab!\n",
    "PROJECT_ROOT = '/notebooks'\n",
    "\n",
    "# Fix this path and use this one on Colab\n",
    "# PROJECT_ROOT = '/content/drive/MyDrive/TeamX'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from os.path import join as ospj\n",
    "sys.path.append(ospj(PROJECT_ROOT, 'src'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-20T08:15:08.258885Z",
     "iopub.status.busy": "2023-07-20T08:15:08.258412Z",
     "iopub.status.idle": "2023-07-20T08:15:08.340349Z",
     "shell.execute_reply": "2023-07-20T08:15:08.338963Z",
     "shell.execute_reply.started": "2023-07-20T08:15:08.258831Z"
    },
    "id": "GRJWZUMgOCAJ",
    "outputId": "384b37ee-cc73-4c08-a840-655b8f105779"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trainer\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "trainer.model.cpu()\n",
    "del trainer.model\n",
    "del trainer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "del train_loader\n",
    "del val_loader\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-21T12:44:43.874267Z",
     "iopub.status.busy": "2023-07-21T12:44:43.873854Z",
     "iopub.status.idle": "2023-07-21T12:44:46.858966Z",
     "shell.execute_reply": "2023-07-21T12:44:46.857933Z",
     "shell.execute_reply.started": "2023-07-21T12:44:43.874239Z"
    },
    "id": "xx15rC_qKhhd",
    "outputId": "61c242ca-7c9d-4528-be66-7abb4096196e"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maimport\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-ConfigParser # Due to an issue of pickle and auto_reload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m config \u001b[38;5;241m=\u001b[39m ConfigParser\u001b[38;5;241m.\u001b[39mwo_args(config\u001b[38;5;241m=\u001b[39mospj(PROJECT_ROOT,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcfgs/project/gradient-config-hppw.json\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_loader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m datamodule\u001b[38;5;241m.\u001b[39mget_loader()\n\u001b[1;32m     19\u001b[0m datamodule \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39minit_obj(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation_loader\u001b[39m\u001b[38;5;124m'\u001b[39m, module_data)\n",
      "File \u001b[0;32m/notebooks/src/utils/config_parser.py:120\u001b[0m, in \u001b[0;36mConfigParser.init_obj\u001b[0;34m(self, name, module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m([k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m module_args \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kwargs]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverwriting kwargs given in config file is not allowed\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    119\u001b[0m module_args\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/src/data/threeDPW.py:80\u001b[0m, in \u001b[0;36mThreeDPWTFRecordDataset.__init__\u001b[0;34m(self, data_path, n_scenes, person_id, subsample, history_window, future_window, batch_size, resize, shuffle, n_workers, prefetch_factor, transforms)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_data_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;241m=\u001b[39m transforms\n\u001b[0;32m---> 80\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/notebooks/src/data/threeDPW.py:126\u001b[0m, in \u001b[0;36mThreeDPWTFRecordDataset._cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Iterate over each scene\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scene_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset:\n\u001b[1;32m    127\u001b[0m     num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;66;03m# Generate windowed representation by adding an extra dimension \u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/tfrecord/reader.py:221\u001b[0m, in \u001b[0;36mexample_loader\u001b[0;34m(data_path, index_path, description, shard, compression_type)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m record_iterator:\n\u001b[1;32m    220\u001b[0m     example \u001b[38;5;241m=\u001b[39m example_pb2\u001b[38;5;241m.\u001b[39mExample()\n\u001b[0;32m--> 221\u001b[0m     \u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mParseFromString\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m extract_feature_dict(example\u001b[38;5;241m.\u001b[39mfeatures, description, typename_mapping)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize the 2D trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw_trainer import HPPWTrainer\n",
    "from utils.config_parser import ConfigParser\n",
    "import data.threeDPW as module_data\n",
    "from utils.io import seed_everything\n",
    "\n",
    "# For fair comparisons\n",
    "seed_everything(100)\n",
    "\n",
    "%aimport -ConfigParser # Due to an issue of pickle and auto_reload\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/gradient-config-hppw.json'))\n",
    "\n",
    "datamodule = config.init_obj('train_loader', module_data)\n",
    "train_loader = datamodule.get_loader()\n",
    "\n",
    "datamodule = config.init_obj('validation_loader', module_data)\n",
    "val_loader = datamodule.get_loader()\n",
    "\n",
    "trainer = HPPWTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss']['train'], label='train')\n",
    "plt.plot(stats['loss']['val'], label='val')\n",
    "plt.title('Classification loss history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-21T19:04:45.240652Z",
     "iopub.status.busy": "2023-07-21T19:04:45.240000Z",
     "iopub.status.idle": "2023-07-21T19:10:08.727691Z",
     "shell.execute_reply": "2023-07-21T19:10:08.726125Z",
     "shell.execute_reply.started": "2023-07-21T19:04:45.240617Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33masim-98-12-26\u001b[0m (\u001b[33mteam-17\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/src/notebooks/wandb/run-20230721_190450-1j52f8ok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/team-17/human-pose-prediction-in-the-wild/runs/1j52f8ok\" target=\"_blank\">quiet-flower-96</a></strong> to <a href=\"https://wandb.ai/team-17/human-pose-prediction-in-the-wild\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "==> Start Training Epoch 1/40, lr=0.010000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch: 1 loss2d: 0.186177 vim2d: 88.57244: : 100% 9152/9152 [05:14<00:00, 34.84it/s] "
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m datamodule\u001b[38;5;241m.\u001b[39mget_loader()\n\u001b[1;32m     22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m HPPW3DTrainer(config\u001b[38;5;241m=\u001b[39mconfig, train_loader\u001b[38;5;241m=\u001b[39mtrain_loader, eval_loader\u001b[38;5;241m=\u001b[39mval_loader)\n\u001b[0;32m---> 23\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss2d\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain2d\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss2d\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval2d\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/notebooks/src/trainers/base3d.py:106\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_epoch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_epoch \u001b[38;5;241m=\u001b[39m epoch\n\u001b[0;32m--> 106\u001b[0m     train_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     states[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss2d\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss2d\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_projection:\n",
      "File \u001b[0;32m/notebooks/src/trainers/hppw3d_trainer.py:169\u001b[0m, in \u001b[0;36mHPPW3DTrainer._train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# if batch_idx % self.log_step == 0:\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m#     # self.logger.debug('Train Epoch: {} Loss: {:.6f}'.format(self.current_epoch, loss.item()))\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m#     ## Log to Tensorboard\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m#     if self.writer is not None:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m#         self.writer.add_image('input_train', make_grid(history.cpu(), nrow=8, normalize=True))\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_loader\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[0;32m--> 169\u001b[0m log_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_metrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/notebooks/src/utils/io.py:98\u001b[0m, in \u001b[0;36mMetricTracker.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg(key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics_dict}\n",
      "File \u001b[0;32m/notebooks/src/utils/io.py:98\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mavg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics_dict}\n",
      "File \u001b[0;32m/notebooks/src/utils/io.py:95\u001b[0m, in \u001b[0;36mMetricTracker.avg\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mavg\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "\"\"\" Initialize the 3D trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw3d_trainer import HPPW3DTrainer\n",
    "from utils.config_parser import ConfigParser\n",
    "import data.threeDPW as module_data\n",
    "from utils.io import seed_everything\n",
    "\n",
    "# For fair comparisons\n",
    "seed_everything(599)\n",
    "\n",
    "%aimport -ConfigParser # Due to an issue of pickle and auto_reload\n",
    "config = ConfigParser.wo_args(config=ospj(PROJECT_ROOT,'cfgs/project/gradient-config-hppw3d.json'))\n",
    "\n",
    "datamodule = config.init_obj('train_loader', module_data)\n",
    "train_loader = datamodule.get_loader()\n",
    "\n",
    "datamodule = config.init_obj('validation_loader', module_data)\n",
    "val_loader = datamodule.get_loader()\n",
    "\n",
    "trainer = HPPW3DTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss2d']['train'], label='train2d')\n",
    "plt.plot(stats['loss2d']['val'], label='val2d')\n",
    "plt.plot(stats['loss3d']['train'], label='train3d')\n",
    "plt.plot(stats['loss3d']['val'], label='va3dl')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('mpjpe')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3QIsVuEhKhhe"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "collapsed": true,
    "id": "29KWrFViKhhf",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "4e1e17a8-feac-4200-f12b-9cdeb2410560"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/203 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b387e738a317>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/hppw/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, history, future, is_teacher_forcing)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mmemory_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_seq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munroll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munroll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# Get combined* local and global features from sequences of poses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/hppw/model.py\u001b[0m in \u001b[0;36mimage_encoding\u001b[0;34m(self, img_seq, mask, unroll)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;31m# Out Shape: (batch_size*history_window, num_patches + 1, E) and (batch_size*history_window, E)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mmemory_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_global\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# Out Shape: (batch_size, history_window, num_patches + 1, E) and (batch_size, history_window, E)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, key_padding_mask)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcls_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls_mask\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mkey_padding_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;31m# Take out the CLS token (in fact \"tokens\" because we have a batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, key_padding_mask)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Take a subset of pretrained encoder layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Final layer norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/sequential.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, key_padding_mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/drive/MyDrive/human-pose-prediction-in-the-wild/src/models/vit/encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, key_padding_mask)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1206\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5223\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0min_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is False but in_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5224\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_in_projection_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5226\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is True but q_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4764\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4765\u001b[0;31m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4766\u001b[0m             \u001b[0;31m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4767\u001b[0m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 94.00 MiB (GPU 0; 14.75 GiB total capacity; 14.32 GiB already allocated; 832.00 KiB free; 14.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "for i, (history, future) in enumerate(tqdm(val_loader)):\n",
    "    output = trainer.model(history, future)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WBrHWH-LUI3d",
    "outputId": "7c2d8240-38f0-4a54-e98a-0ec7bfafc41a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 10, 19, 3])\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T23:02:03.602682Z",
     "iopub.status.busy": "2023-07-19T23:02:03.602041Z",
     "iopub.status.idle": "2023-07-19T23:02:06.347966Z",
     "shell.execute_reply": "2023-07-19T23:02:06.347157Z",
     "shell.execute_reply.started": "2023-07-19T23:02:03.602622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-19T23:02:06.349441Z",
     "iopub.status.busy": "2023-07-19T23:02:06.349225Z",
     "iopub.status.idle": "2023-07-19T23:02:06.436987Z",
     "shell.execute_reply": "2023-07-19T23:02:06.436405Z",
     "shell.execute_reply.started": "2023-07-19T23:02:06.349422Z"
    },
    "id": "i8oRVKzyKhhf",
    "outputId": "33dd751c-ab3f-4397-98e3-fe09c2ebed17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                                                      Param #\n",
       "====================================================================================================\n",
       "HumanPosePredictorModel3D                                                   --\n",
       "├─PoseEncoder: 1-1                                                          --\n",
       "│    └─Sequential: 2-1                                                      --\n",
       "│    │    └─PoseEncoderBlock: 3-1                                           527,104\n",
       "│    │    └─PoseEncoderBlock: 3-2                                           527,104\n",
       "├─VisionTransformer: 1-2                                                    768\n",
       "│    └─Conv2d: 2-2                                                          590,592\n",
       "│    └─Encoder: 2-3                                                         151,296\n",
       "│    │    └─MultiInputSequential: 3-3                                       14,175,744\n",
       "│    │    └─LayerNorm: 3-4                                                  1,536\n",
       "│    └─Sequential: 2-4                                                      --\n",
       "│    │    └─Linear: 3-5                                                     769,000\n",
       "│    └─Linear: 2-5                                                          196,864\n",
       "│    └─MaxPool2d: 2-6                                                       --\n",
       "├─TemporalEncoder: 1-3                                                      --\n",
       "│    └─TemporalMultiInputSequential: 2-7                                    --\n",
       "│    │    └─TemporalEncoderBlock: 3-6                                       1,582,336\n",
       "│    │    └─TemporalEncoderBlock: 3-7                                       1,582,336\n",
       "├─TemporalEncoder: 1-4                                                      --\n",
       "│    └─TemporalMultiInputSequential: 2-8                                    --\n",
       "│    │    └─TemporalEncoderBlock: 3-8                                       1,582,336\n",
       "│    │    └─TemporalEncoderBlock: 3-9                                       1,582,336\n",
       "├─PoseDecoder: 1-5                                                          --\n",
       "│    └─MultiheadAttention: 2-9                                              197,376\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-10                           65,792\n",
       "│    └─TransformerDecoderLayer: 2-10                                        --\n",
       "│    │    └─MultiheadAttention: 3-11                                        263,168\n",
       "│    │    └─MultiheadAttention: 3-12                                        263,168\n",
       "│    │    └─Linear: 3-13                                                    65,792\n",
       "│    │    └─Dropout: 3-14                                                   --\n",
       "│    │    └─Linear: 3-15                                                    65,792\n",
       "│    │    └─LayerNorm: 3-16                                                 512\n",
       "│    │    └─LayerNorm: 3-17                                                 512\n",
       "│    │    └─LayerNorm: 3-18                                                 512\n",
       "│    │    └─Dropout: 3-19                                                   --\n",
       "│    │    └─Dropout: 3-20                                                   --\n",
       "│    │    └─Dropout: 3-21                                                   --\n",
       "│    └─LayerNorm: 2-11                                                      512\n",
       "│    └─MLPBlock: 2-12                                                       --\n",
       "│    │    └─Linear: 3-22                                                    131,584\n",
       "│    │    └─GELU: 3-23                                                      --\n",
       "│    │    └─Dropout: 3-24                                                   --\n",
       "│    │    └─Linear: 3-25                                                    131,328\n",
       "│    │    └─Dropout: 3-26                                                   --\n",
       "│    └─TransformerDecoder: 2-13                                             --\n",
       "│    │    └─ModuleList: 3-27                                                1,318,912\n",
       "│    └─TemporalEncoder: 2-14                                                --\n",
       "│    │    └─TemporalMultiInputSequential: 3-28                              2,110,464\n",
       "├─FourierMLPEncoding: 1-6                                                   --\n",
       "│    └─Sequential: 2-15                                                     --\n",
       "│    │    └─Linear: 3-29                                                    33,152\n",
       "│    │    └─ReLU: 3-30                                                      --\n",
       "│    │    └─Linear: 3-31                                                    33,024\n",
       "├─FourierMLPEncoding: 1-7                                                   --\n",
       "│    └─Sequential: 2-16                                                     --\n",
       "│    │    └─Linear: 3-32                                                    65,920\n",
       "│    │    └─ReLU: 3-33                                                      --\n",
       "│    │    └─Linear: 3-34                                                    33,024\n",
       "├─Linear: 1-8                                                               514\n",
       "├─LinearProjection: 1-9                                                     --\n",
       "│    └─MLPBlock: 2-17                                                       --\n",
       "│    │    └─Linear: 3-35                                                    4,992\n",
       "│    │    └─Dropout: 3-36                                                   --\n",
       "│    └─MLPBlock: 2-18                                                       --\n",
       "│    │    └─Linear: 3-37                                                    9,675\n",
       "│    │    └─Dropout: 3-38                                                   --\n",
       "====================================================================================================\n",
       "Total params: 28,065,077\n",
       "Trainable params: 28,065,077\n",
       "Non-trainable params: 0\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchinfo\n",
    "torchinfo.summary(trainer.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfGMPX6VKhhg"
   },
   "outputs": [],
   "source": [
    "\"\"\" Perform test\n",
    "\"\"\"\n",
    "\n",
    "checkpoint_dir = '0604_104809'\n",
    "path = ospj(PROJECT_ROOT, f'saved/models/hppw/{checkpoint_dir}/best_val_model.pth')\n",
    "\n",
    "trainer.load_model(path=path)\n",
    "\n",
    "result = trainer.evaluate(loader=test_loader)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AAaJjowKhhg"
   },
   "outputs": [],
   "source": [
    "from models.temporal.encoder import TemporalEncoder, LocalTemporalEncoderBlock\n",
    "\n",
    "model = TemporalEncoder(\n",
    "    num_layers=3,\n",
    "    num_heads=8,\n",
    "    hidden_dim=256,\n",
    "    mlp_dim=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdXvEna-Khhg"
   },
   "outputs": [],
   "source": [
    "local_feat = torch.randn(size=(32, 15, 197, 256))\n",
    "global_feat = torch.randn(size=(32, 15, 256))\n",
    "\n",
    "local_out, global_out = model(local_feat, global_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gObtAvw7Khhg",
    "outputId": "c8b20db4-d18a-4d69-d9df-81afea09b144"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6335],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6336],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6336],\n",
       "         ...,\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6335],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6335],\n",
       "         [ 0.7680,  0.1498,  2.5715,  ..., -1.7233, -7.7865,  8.6336]],\n",
       "\n",
       "        [[-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         ...,\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401],\n",
       "         [-1.2756, -7.0257, -1.1117,  ...,  4.7989, -0.6455,  3.4401]],\n",
       "\n",
       "        [[-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         ...,\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397],\n",
       "         [-1.1115, -3.7773, -9.5381,  ..., -0.7923,  2.3916, -3.7397]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         ...,\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412],\n",
       "         [-8.3675,  3.4321,  6.9062,  ...,  4.1495,  4.4776, -3.2412]],\n",
       "\n",
       "        [[-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         ...,\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081],\n",
       "         [-3.0640, -2.3856, -8.3690,  ...,  7.7114,  0.1572, -4.7081]],\n",
       "\n",
       "        [[ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         ...,\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966],\n",
       "         [ 7.2000,  4.8411, 12.4626,  ..., -1.2724,  1.8068,  3.4966]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AI02lLoOKhhg",
    "outputId": "4d1708e1-6d98-4ed6-ceac-0c62b89c9e18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "├─MultiInputSequential: 1-1                        [-1, 197, 256]            --\n",
      "|    └─TemporalEncoderBlock: 2-1                   [-1, 14, 197, 256]        --\n",
      "|    |    └─LocalTemporalEncoderBlock: 3-1         [-1, 14, 197, 256]        528,128\n",
      "|    |    └─GlobalTemporalEncoderBlock: 3-2        [-1, 15, 256]             527,104\n",
      "|    └─TemporalEncoderBlock: 2-2                   [-1, 13, 197, 256]        --\n",
      "|    |    └─LocalTemporalEncoderBlock: 3-3         [-1, 13, 197, 256]        528,128\n",
      "|    |    └─GlobalTemporalEncoderBlock: 3-4        [-1, 15, 256]             527,104\n",
      "|    └─TemporalEncoderBlock: 2-3                   [-1, 197, 256]            --\n",
      "|    |    └─LocalTemporalEncoderBlock: 3-5         [-1, 197, 256]            528,128\n",
      "|    |    └─GlobalTemporalEncoderBlock: 3-6        [-1, 15, 256]             527,104\n",
      "====================================================================================================\n",
      "Total params: 3,165,696\n",
      "Trainable params: 3,165,696\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 21.54\n",
      "====================================================================================================\n",
      "Input size (MB): 92.81\n",
      "Forward/backward pass size (MB): 4.02\n",
      "Params size (MB): 12.08\n",
      "Estimated Total Size (MB): 108.91\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "├─MultiInputSequential: 1-1                        [-1, 197, 256]            --\n",
       "|    └─TemporalEncoderBlock: 2-1                   [-1, 14, 197, 256]        --\n",
       "|    |    └─LocalTemporalEncoderBlock: 3-1         [-1, 14, 197, 256]        528,128\n",
       "|    |    └─GlobalTemporalEncoderBlock: 3-2        [-1, 15, 256]             527,104\n",
       "|    └─TemporalEncoderBlock: 2-2                   [-1, 13, 197, 256]        --\n",
       "|    |    └─LocalTemporalEncoderBlock: 3-3         [-1, 13, 197, 256]        528,128\n",
       "|    |    └─GlobalTemporalEncoderBlock: 3-4        [-1, 15, 256]             527,104\n",
       "|    └─TemporalEncoderBlock: 2-3                   [-1, 197, 256]            --\n",
       "|    |    └─LocalTemporalEncoderBlock: 3-5         [-1, 197, 256]            528,128\n",
       "|    |    └─GlobalTemporalEncoderBlock: 3-6        [-1, 15, 256]             527,104\n",
       "====================================================================================================\n",
       "Total params: 3,165,696\n",
       "Trainable params: 3,165,696\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 21.54\n",
       "====================================================================================================\n",
       "Input size (MB): 92.81\n",
       "Forward/backward pass size (MB): 4.02\n",
       "Params size (MB): 12.08\n",
       "Estimated Total Size (MB): 108.91\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, input_data=[local_feat, global_feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDLiJsFrKhhh",
    "outputId": "250e8f61-3e4b-4680-cb43-5f02fab5ec99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: There's no GPU available on this machine,training will be performed on CPU.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'wandb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrainers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhppw_trainer\u001b[39;00m \u001b[39mimport\u001b[39;00m HPPWTrainer\n\u001b[1;32m----> 7\u001b[0m trainer \u001b[39m=\u001b[39m HPPWTrainer(config\u001b[39m=\u001b[39;49mconfig, train_loader\u001b[39m=\u001b[39;49mtrain_loader, eval_loader\u001b[39m=\u001b[39;49mval_loader)\n\u001b[0;32m      8\u001b[0m \u001b[39m# stats = trainer.train()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m plt\u001b[39m.\u001b[39mplot(stats[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m], label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\\../..\\src\\trainers\\hppw_trainer.py:24\u001b[0m, in \u001b[0;36mHPPWTrainer.__init__\u001b[1;34m(self, config, train_loader, eval_loader)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, config, train_loader, eval_loader\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     20\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39m    Create the model, loss criterion, optimizer, and dataloaders\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m    And anything else that might be needed during training. (e.g. device type)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(config)    \n\u001b[0;32m     25\u001b[0m     \u001b[39m# build model architecture, then print to console\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39minit_obj(\u001b[39m'\u001b[39m\u001b[39march\u001b[39m\u001b[39m'\u001b[39m, module_arch)\n",
      "File \u001b[1;32md:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\\../..\\src\\trainers\\base.py:92\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39m# prepare for (multi-device) GPU training\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# This part doesn't do anything if you don't have a GPU.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_device_ids \u001b[39m=\u001b[39m prepare_device(config[\u001b[39m'\u001b[39m\u001b[39mn_gpu\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 92\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwandb_enabled \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39;49m\u001b[39mwandb\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[0;32m     93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwandb_enabled \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mwandb\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32md:\\Saarland\\Research\\human-pose-prediction-in-the-wild\\src\\notebooks\\../..\\src\\utils\\config_parser.py:139\u001b[0m, in \u001b[0;36mConfigParser.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m    138\u001b[0m     \u001b[39m\"\"\"Access items like ordinary dict.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[name]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'wandb'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Initialize the trainer and model\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from trainers.hppw_trainer import HPPWTrainer\n",
    "\n",
    "trainer = HPPWTrainer(config=config, train_loader=train_loader, eval_loader=val_loader)\n",
    "# stats = trainer.train()\n",
    "\n",
    "plt.plot(stats['loss']['train'], label='train')\n",
    "plt.plot(stats['loss']['val'], label='val')\n",
    "plt.title('Classification loss history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9R5N7uoRKhhh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
